{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>122075</td>\n",
       "      <td>450</td>\n",
       "      <td>94</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106461</td>\n",
       "      <td>354</td>\n",
       "      <td>1036</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140686</td>\n",
       "      <td>550</td>\n",
       "      <td>1341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163565</td>\n",
       "      <td>734</td>\n",
       "      <td>654</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138440</td>\n",
       "      <td>530</td>\n",
       "      <td>1120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        movie_id  user_id  rating\n",
       "122075       450       94     3.0\n",
       "106461       354     1036     1.0\n",
       "140686       550     1341     1.0\n",
       "163565       734      654     3.0\n",
       "138440       530     1120     1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ratings.csv', sep=',')\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 122075 to 71769\n",
      "Data columns (total 3 columns):\n",
      "movie_id    200000 non-null int64\n",
      "user_id     200000 non-null int64\n",
      "rating      200000 non-null float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 6.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>424.530130</td>\n",
       "      <td>932.984750</td>\n",
       "      <td>2.264930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>330.797529</td>\n",
       "      <td>541.660646</td>\n",
       "      <td>1.494531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>942.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1681.000000</td>\n",
       "      <td>1885.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            movie_id        user_id         rating\n",
       "count  200000.000000  200000.000000  200000.000000\n",
       "mean      424.530130     932.984750       2.264930\n",
       "std       330.797529     541.660646       1.494531\n",
       "min         0.000000       0.000000       1.000000\n",
       "25%       174.000000     446.000000       1.000000\n",
       "50%       321.000000     942.500000       1.000000\n",
       "75%       630.000000    1389.000000       4.000000\n",
       "max      1681.000000    1885.000000       5.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.loc[:,['movie_id', 'user_id']].values[:160000,:]\n",
    "Y_train = data.loc[:,['rating']].values[:160000,:]\n",
    "\n",
    "X_test = data.loc[:,['movie_id', 'user_id']].values[160000:,:]\n",
    "Y_test = data.loc[:,['rating']].values[160000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer1():\n",
    "    \n",
    "    def __init__(self, model, input_dim, rank):\n",
    "        self.model = model\n",
    "        self.input_dim = input_dim\n",
    "        self.rank = rank\n",
    "        self.build()\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        weight_init = tf.random.normal(shape=shape, mean=0.0, stddev=0.05, dtype=\"float32\")\n",
    "        return tf.Variable(initial_value=weight_init, trainable=True)\n",
    "        \n",
    "    def build(self):\n",
    "        self.w = self.add_weight(shape=(self.input_dim,self.rank))\n",
    "        self.weights = [self.w]\n",
    "\n",
    "    def __call__(self, inputs):        \n",
    "        idx = tf.reshape(tf.cast(tf.abs(inputs), dtype='int32'),[-1])\n",
    "        return tf.gather(self.w, indices=idx, axis=0)\n",
    "    \n",
    "class Layer2():\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.weights = []\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        a1 = inputs[0]\n",
    "        a2 = inputs[1]\n",
    "        return tf.concat(values=[a1,a2], axis=1)\n",
    "    \n",
    "class Layer3():\n",
    "    \n",
    "    def __init__(self, model, input_dim, output_dim):\n",
    "        self.model = model\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.build()\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        weight_init = tf.random.normal(shape=shape, mean=0.0, stddev=0.05, dtype=\"float32\")\n",
    "        return tf.Variable(initial_value=weight_init, trainable=True)\n",
    "        \n",
    "    def build(self):\n",
    "        self.w = self.add_weight(shape=(self.output_dim, self.input_dim))\n",
    "        self.b = self.add_weight(shape=(self.output_dim, 1))\n",
    "        self.weights = [self.w, self.b]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        z = tf.matmul(self.w, tf.transpose(inputs)) + self.b\n",
    "        u = tf.transpose(z)\n",
    "        return tf.math.maximum(0.,u)\n",
    "    \n",
    "class Layer4():\n",
    "    \n",
    "    def __init__(self, model, input_dim, output_dim):\n",
    "        self.model = model\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.build()\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        weight_init = tf.random.normal(shape=shape, mean=0.0, stddev=0.05, dtype=\"float32\")\n",
    "        return tf.Variable(initial_value=weight_init, trainable=True)\n",
    "        \n",
    "    def build(self):\n",
    "        self.w = self.add_weight(shape=(self.output_dim, self.input_dim))\n",
    "        self.b = self.add_weight(shape=(self.output_dim, 1))\n",
    "        self.weights = [self.w, self.b]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        z = tf.matmul(self.w, tf.transpose(inputs)) + self.b\n",
    "        u = tf.transpose(z)\n",
    "        return 4*tf.math.sigmoid(u)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction():\n",
    "        \n",
    "    def __init__(self, model, alpha):\n",
    "        self.model = model\n",
    "        self.alpha = alpha\n",
    "            \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        loss = tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "        regularization = 0\n",
    "        for i in range(len(self.model.weights)):\n",
    "            regularization = regularization + tf.reduce_sum(tf.math.square(self.model.weights[i]))\n",
    "        return loss + self.alpha*regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricFunction():\n",
    "                    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.square(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Optimizer():\n",
    "\n",
    "    def __init__(self, model, learning_rate, beta_1, beta_2, epsilon):\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon= epsilon\n",
    "        self.stop_training = False\n",
    "        self.build()\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        weight_init = tf.zeros(shape=shape, dtype=\"float32\")\n",
    "        return  tf.Variable(initial_value=weight_init, trainable=False)\n",
    "    \n",
    "    def build(self):\n",
    "        self.weights = []\n",
    "        for weight in self.model.weights:\n",
    "            m = self.add_weight(shape=weight.shape)\n",
    "            v = self.add_weight(shape=weight.shape)\n",
    "            self.weights.append([m,v])\n",
    "            \n",
    "    def apply(self, grads, weights):\n",
    "        for i in range(len(weights)):\n",
    "            w = weights[i]\n",
    "            grad_w = grads[i]\n",
    "            m = self.weights[i][0]\n",
    "            v = self.weights[i][1]\n",
    "            self.weights[i][0].assign(self.beta_1*m + (1-self.beta_1)*grad_w)  \n",
    "            self.weights[i][1].assign(self.beta_2*v + (1-self.beta_2)*grad_w*grad_w)\n",
    "            m_ = (1/(1-self.beta_1))*self.weights[i][0]\n",
    "            v_ = (1/(1-self.beta_2))*self.weights[i][1]\n",
    "            weights[i].assign(w - self.learning_rate*m_/(tf.math.sqrt(v_)+self.epsilon))\n",
    "            \n",
    "    def train_step(self, X, Y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            H = self.model(X)\n",
    "            loss = self.model.loss(Y, H)\n",
    "        grads = tape.gradient(loss, self.model.weights)\n",
    "        self.apply(grads, self.model.weights)\n",
    "        H = self.model(X)\n",
    "        loss = self.model.loss(Y, H)\n",
    "        metric = self.model.metric(Y, H)\n",
    "        logs = {'loss': loss,\n",
    "                'metric': metric}\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback1():\n",
    "\n",
    "    def __init__(self, model, verbose):\n",
    "        self.model = model\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = tf.timestamp()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.verbose:\n",
    "            now = tf.timestamp()\n",
    "            time = now - self.start_time\n",
    "            tf.print('Epochs {}/{} - Loss: {} - Metric: {}'.format(epoch+1, self.model.epochs, logs['loss'], logs['metric']))\n",
    "            tf.print('----- {}s -----'.format(tf.round(1000*time)/1000))\n",
    "            \n",
    "class Callback2():\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.history = {'loss':[],\n",
    "                        'metric':[]}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.history['loss'].append(logs['loss'].numpy())\n",
    "        self.history['metric'].append(logs['metric'].numpy())\n",
    "        \n",
    "    def on_train_end(self):\n",
    "        self.model.history = self.history\n",
    "\n",
    "class Callback3():\n",
    "        \n",
    "    def __init__(self, model, patience, error, reduce_factor, min_learning_rate):\n",
    "        self.model = model\n",
    "        self.patience = patience\n",
    "        self.error = error\n",
    "        self.reduce_factor = reduce_factor\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "                        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch==0:\n",
    "            self.loss = logs['loss']\n",
    "            self.non_decreasing_epochs = 0\n",
    "        else:\n",
    "            if ((self.loss-logs['loss'])>self.error):\n",
    "                self.loss = logs['loss']\n",
    "                self.non_decreasing_epochs = 0\n",
    "            else:\n",
    "                self.non_decreasing_epochs = self.non_decreasing_epochs+1\n",
    "        if (self.non_decreasing_epochs == self.patience):\n",
    "            if (self.model.optimizer.learning_rate>self.min_learning_rate):\n",
    "                self.model.optimizer.learning_rate = self.reduce_factor*self.model.optimizer.learning_rate\n",
    "                self.non_decreasing_epochs = 0\n",
    "        \n",
    "class Callback4():\n",
    "        \n",
    "    def __init__(self, model, patience, error):\n",
    "        self.model = model\n",
    "        self.patience = patience\n",
    "        self.error = error\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch==0:\n",
    "            self.loss = logs['loss']\n",
    "            self.non_decreasing_epochs = 0\n",
    "        else:\n",
    "            if ((self.loss-logs['loss'])>self.error):\n",
    "                self.loss = logs['loss']\n",
    "                self.non_decreasing_epochs = 0\n",
    "            else:\n",
    "                self.non_decreasing_epochs = self.non_decreasing_epochs+1\n",
    "        if (self.non_decreasing_epochs == self.patience):\n",
    "            self.model.optimizer.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderSystem():\n",
    "    \n",
    "    def __init__(self, movies_dim, users_dim, rank, hidden_dim, output_dim):\n",
    "        self.movies_dim = movies_dim\n",
    "        self.users_dim = users_dim\n",
    "        self.rank = rank\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.ouput_dim = output_dim\n",
    "        self.build()\n",
    "     \n",
    "    def build(self):\n",
    "        self.h1 = Layer1(model=self, input_dim=self.movies_dim, rank=self.rank)\n",
    "        self.h2 = Layer1(model=self, input_dim=self.users_dim, rank=self.rank)\n",
    "        self.h3 = Layer2(model=self)\n",
    "        self.h4 = Layer3(model=self, input_dim=2*self.rank, output_dim=self.hidden_dim)\n",
    "        self.h5 = Layer4(model=self, input_dim=self.hidden_dim, output_dim=self.ouput_dim)\n",
    "        self.layers = [self.h1, self.h2, self.h3, self.h4, self.h5]\n",
    "        self.weights = []\n",
    "        for layer in self.layers:\n",
    "            for weight in layer.weights:\n",
    "                self.weights.append(weight)\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        x0 = inputs[0]\n",
    "        x1 = self.h1(x0)\n",
    "        z0 = inputs[1]\n",
    "        z1 = self.h2(z0)\n",
    "        y0 = self.h3([x1,z1]) \n",
    "        y1 = self.h4(y0)\n",
    "        y2 = self.h5(y1)\n",
    "        return y2\n",
    "        \n",
    "    def train_setup(self, epochs, learning_rate, alpha, beta_1, beta_2, epsilon, verbose):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.alpha = alpha\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.verbose = verbose\n",
    "        self.loss = LossFunction(model=self, alpha=self.alpha)\n",
    "        self.metric = MetricFunction(model=self)\n",
    "        self.optimizer = Optimizer(model=self, learning_rate=self.learning_rate, beta_1=self.beta_1, beta_2=self.beta_2, epsilon=self.epsilon)\n",
    "        self.callbacks = [Callback1(model=self, verbose=self.verbose),\n",
    "                          Callback2(model=self),\n",
    "                          Callback3(model=self, patience=100, error=0.0001, reduce_factor=0.1, min_learning_rate=0.001),\n",
    "                          Callback4(model=self, patience=200, error=0.0001)]\n",
    "\n",
    "    def fit(self, X, Y, epochs=1000, learning_rate=0.01, alpha=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, verbose=True):\n",
    "        self.train_setup(epochs, learning_rate, alpha, beta_1, beta_2, epsilon, verbose)\n",
    "        if verbose:\n",
    "            tf.print('Train on {} samples'.format(X.shape[0]))\n",
    "        for epoch in range(epochs):\n",
    "            self.callbacks[0].on_epoch_begin(epoch)\n",
    "            logs = self.optimizer.train_step([tf.constant(X[:,[0]], dtype=\"int32\"), tf.constant(X[:,[1]], dtype=\"int32\")], tf.constant(Y, dtype=\"float32\"))\n",
    "            for callback in self.callbacks:\n",
    "                callback.on_epoch_end(epoch, logs)\n",
    "            if self.optimizer.stop_training:\n",
    "                break\n",
    "        self.callbacks[1].on_train_end()\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return self([tf.constant(inputs[:,[0]], dtype=\"float32\"), tf.constant(inputs[:,[1]], dtype=\"float32\")]).numpy()\n",
    "        \n",
    "    def evaluate(self, X, Y):    \n",
    "        loss = self.loss(tf.constant(Y, dtype=\"float32\"), self([tf.constant(X[:,[0]], dtype=\"float32\"), tf.constant(X[:,[1]], dtype=\"float32\")]))\n",
    "        loss_numpy = loss.numpy()\n",
    "        metric = self.metric(tf.constant(Y, dtype=\"float32\"), self([tf.constant(X[:,[0]], dtype=\"float32\"), tf.constant(X[:,[1]], dtype=\"float32\")]))\n",
    "        metric_numpy = metric.numpy()\n",
    "        tf.print('Loss: {} - Metric: {}'.format(loss_numpy, metric_numpy))\n",
    "        return [loss_numpy, metric_numpy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160000 samples\n",
      "Epochs 1/1000 - Loss: 3.329958438873291 - Metric: 2.67433500289917\n",
      "----- 0.325s -----\n",
      "Epochs 2/1000 - Loss: 3.0494141578674316 - Metric: 2.638071298599243\n",
      "----- 0.193s -----\n",
      "Epochs 3/1000 - Loss: 2.8337724208831787 - Metric: 2.5938498973846436\n",
      "----- 0.164s -----\n",
      "Epochs 4/1000 - Loss: 2.6875689029693604 - Metric: 2.542156934738159\n",
      "----- 0.174s -----\n",
      "Epochs 5/1000 - Loss: 2.5943591594696045 - Metric: 2.4834024906158447\n",
      "----- 0.191s -----\n",
      "Epochs 6/1000 - Loss: 2.533491849899292 - Metric: 2.4197614192962646\n",
      "----- 0.182s -----\n",
      "Epochs 7/1000 - Loss: 2.485748767852783 - Metric: 2.354536533355713\n",
      "----- 0.182s -----\n",
      "Epochs 8/1000 - Loss: 2.442600965499878 - Metric: 2.293335199356079\n",
      "----- 0.181s -----\n",
      "Epochs 9/1000 - Loss: 2.4061851501464844 - Metric: 2.243482828140259\n",
      "----- 0.185s -----\n",
      "Epochs 10/1000 - Loss: 2.382209300994873 - Metric: 2.211669445037842\n",
      "----- 0.184s -----\n",
      "Epochs 11/1000 - Loss: 2.3735594749450684 - Metric: 2.19897723197937\n",
      "----- 0.187s -----\n",
      "Epochs 12/1000 - Loss: 2.3698604106903076 - Metric: 2.1909615993499756\n",
      "----- 0.177s -----\n",
      "Epochs 13/1000 - Loss: 2.351226806640625 - Metric: 2.1632936000823975\n",
      "----- 0.183s -----\n",
      "Epochs 14/1000 - Loss: 2.3080763816833496 - Metric: 2.1025028228759766\n",
      "----- 0.171s -----\n",
      "Epochs 15/1000 - Loss: 2.2431893348693848 - Metric: 2.008019208908081\n",
      "----- 0.19s -----\n",
      "Epochs 16/1000 - Loss: 2.1685612201690674 - Metric: 1.8899980783462524\n",
      "----- 0.18s -----\n",
      "Epochs 17/1000 - Loss: 2.0963943004608154 - Metric: 1.7639080286026\n",
      "----- 0.201s -----\n",
      "Epochs 18/1000 - Loss: 2.032355785369873 - Metric: 1.6441216468811035\n",
      "----- 0.177s -----\n",
      "Epochs 19/1000 - Loss: 1.9756841659545898 - Metric: 1.5376853942871094\n",
      "----- 0.184s -----\n",
      "Epochs 20/1000 - Loss: 1.9186606407165527 - Metric: 1.4423176050186157\n",
      "----- 0.186s -----\n",
      "Epochs 21/1000 - Loss: 1.8581082820892334 - Metric: 1.3566570281982422\n",
      "----- 0.184s -----\n",
      "Epochs 22/1000 - Loss: 1.793576955795288 - Metric: 1.2791318893432617\n",
      "----- 0.181s -----\n",
      "Epochs 23/1000 - Loss: 1.727960228919983 - Metric: 1.2110284566879272\n",
      "----- 0.174s -----\n",
      "Epochs 24/1000 - Loss: 1.6657910346984863 - Metric: 1.153910517692566\n",
      "----- 0.177s -----\n",
      "Epochs 25/1000 - Loss: 1.6121432781219482 - Metric: 1.108102560043335\n",
      "----- 0.184s -----\n",
      "Epochs 26/1000 - Loss: 1.5695174932479858 - Metric: 1.070457935333252\n",
      "----- 0.187s -----\n",
      "Epochs 27/1000 - Loss: 1.5298516750335693 - Metric: 1.03052818775177\n",
      "----- 0.183s -----\n",
      "Epochs 28/1000 - Loss: 1.4941608905792236 - Metric: 0.9923927783966064\n",
      "----- 0.183s -----\n",
      "Epochs 29/1000 - Loss: 1.4636101722717285 - Metric: 0.9568874835968018\n",
      "----- 0.178s -----\n",
      "Epochs 30/1000 - Loss: 1.4374384880065918 - Metric: 0.925544261932373\n",
      "----- 0.181s -----\n",
      "Epochs 31/1000 - Loss: 1.4124259948730469 - Metric: 0.8944546580314636\n",
      "----- 0.185s -----\n",
      "Epochs 32/1000 - Loss: 1.3865668773651123 - Metric: 0.8626826405525208\n",
      "----- 0.171s -----\n",
      "Epochs 33/1000 - Loss: 1.3597111701965332 - Metric: 0.8316949009895325\n",
      "----- 0.191s -----\n",
      "Epochs 34/1000 - Loss: 1.3329553604125977 - Metric: 0.8041723370552063\n",
      "----- 0.204s -----\n",
      "Epochs 35/1000 - Loss: 1.3069988489151 - Metric: 0.7801918983459473\n",
      "----- 0.192s -----\n",
      "Epochs 36/1000 - Loss: 1.2832965850830078 - Metric: 0.7588298320770264\n",
      "----- 0.18s -----\n",
      "Epochs 37/1000 - Loss: 1.2611219882965088 - Metric: 0.7387136220932007\n",
      "----- 0.189s -----\n",
      "Epochs 38/1000 - Loss: 1.2407991886138916 - Metric: 0.7202441692352295\n",
      "----- 0.181s -----\n",
      "Epochs 39/1000 - Loss: 1.2220832109451294 - Metric: 0.7042239308357239\n",
      "----- 0.172s -----\n",
      "Epochs 40/1000 - Loss: 1.205007553100586 - Metric: 0.6905573010444641\n",
      "----- 0.183s -----\n",
      "Epochs 41/1000 - Loss: 1.189265489578247 - Metric: 0.6786359548568726\n",
      "----- 0.18s -----\n",
      "Epochs 42/1000 - Loss: 1.1746702194213867 - Metric: 0.668276846408844\n",
      "----- 0.179s -----\n",
      "Epochs 43/1000 - Loss: 1.1618187427520752 - Metric: 0.6599507927894592\n",
      "----- 0.187s -----\n",
      "Epochs 44/1000 - Loss: 1.150660753250122 - Metric: 0.6532653570175171\n",
      "----- 0.175s -----\n",
      "Epochs 45/1000 - Loss: 1.140913963317871 - Metric: 0.6478818655014038\n",
      "----- 0.19s -----\n",
      "Epochs 46/1000 - Loss: 1.1321406364440918 - Metric: 0.6434212923049927\n",
      "----- 0.186s -----\n",
      "Epochs 47/1000 - Loss: 1.12453031539917 - Metric: 0.6401707530021667\n",
      "----- 0.186s -----\n",
      "Epochs 48/1000 - Loss: 1.117384433746338 - Metric: 0.6369892358779907\n",
      "----- 0.184s -----\n",
      "Epochs 49/1000 - Loss: 1.1104891300201416 - Metric: 0.6329187750816345\n",
      "----- 0.19s -----\n",
      "Epochs 50/1000 - Loss: 1.1036715507507324 - Metric: 0.627244234085083\n",
      "----- 0.19s -----\n",
      "Epochs 51/1000 - Loss: 1.0968749523162842 - Metric: 0.6197404861450195\n",
      "----- 0.184s -----\n",
      "Epochs 52/1000 - Loss: 1.090215802192688 - Metric: 0.6107109189033508\n",
      "----- 0.194s -----\n",
      "Epochs 53/1000 - Loss: 1.0839974880218506 - Metric: 0.6008713245391846\n",
      "----- 0.191s -----\n",
      "Epochs 54/1000 - Loss: 1.0787402391433716 - Metric: 0.5911930203437805\n",
      "----- 0.186s -----\n",
      "Epochs 55/1000 - Loss: 1.0744545459747314 - Metric: 0.5822160840034485\n",
      "----- 0.184s -----\n",
      "Epochs 56/1000 - Loss: 1.0708682537078857 - Metric: 0.5743169784545898\n",
      "----- 0.181s -----\n",
      "Epochs 57/1000 - Loss: 1.0679943561553955 - Metric: 0.5680705308914185\n",
      "----- 0.184s -----\n",
      "Epochs 58/1000 - Loss: 1.065610408782959 - Metric: 0.5635008215904236\n",
      "----- 0.188s -----\n",
      "Epochs 59/1000 - Loss: 1.0632882118225098 - Metric: 0.5600900650024414\n",
      "----- 0.192s -----\n",
      "Epochs 60/1000 - Loss: 1.060974359512329 - Metric: 0.5575085282325745\n",
      "----- 0.183s -----\n",
      "Epochs 61/1000 - Loss: 1.0588340759277344 - Metric: 0.5556808710098267\n",
      "----- 0.187s -----\n",
      "Epochs 62/1000 - Loss: 1.056879997253418 - Metric: 0.5543749928474426\n",
      "----- 0.186s -----\n",
      "Epochs 63/1000 - Loss: 1.0549565553665161 - Metric: 0.5532363653182983\n",
      "----- 0.187s -----\n",
      "Epochs 64/1000 - Loss: 1.053009033203125 - Metric: 0.5521520376205444\n",
      "----- 0.194s -----\n",
      "Epochs 65/1000 - Loss: 1.051259994506836 - Metric: 0.5512663125991821\n",
      "----- 0.193s -----\n",
      "Epochs 66/1000 - Loss: 1.0497894287109375 - Metric: 0.5505114793777466\n",
      "----- 0.187s -----\n",
      "Epochs 67/1000 - Loss: 1.0484973192214966 - Metric: 0.5497178435325623\n",
      "----- 0.183s -----\n",
      "Epochs 68/1000 - Loss: 1.047311544418335 - Metric: 0.5489673018455505\n",
      "----- 0.184s -----\n",
      "Epochs 69/1000 - Loss: 1.0461575984954834 - Metric: 0.5482680797576904\n",
      "----- 0.197s -----\n",
      "Epochs 70/1000 - Loss: 1.045058250427246 - Metric: 0.547605037689209\n",
      "----- 0.207s -----\n",
      "Epochs 71/1000 - Loss: 1.0440675020217896 - Metric: 0.5469628572463989\n",
      "----- 0.208s -----\n",
      "Epochs 72/1000 - Loss: 1.0431556701660156 - Metric: 0.5463559627532959\n",
      "----- 0.189s -----\n",
      "Epochs 73/1000 - Loss: 1.0422732830047607 - Metric: 0.5456531047821045\n",
      "----- 0.192s -----\n",
      "Epochs 74/1000 - Loss: 1.0414330959320068 - Metric: 0.5447892546653748\n",
      "----- 0.202s -----\n",
      "Epochs 75/1000 - Loss: 1.0406739711761475 - Metric: 0.5437597036361694\n",
      "----- 0.2s -----\n",
      "Epochs 76/1000 - Loss: 1.0399736166000366 - Metric: 0.5426952242851257\n",
      "----- 0.196s -----\n",
      "Epochs 77/1000 - Loss: 1.0393126010894775 - Metric: 0.5416648983955383\n",
      "----- 0.194s -----\n",
      "Epochs 78/1000 - Loss: 1.0387065410614014 - Metric: 0.5407132506370544\n",
      "----- 0.181s -----\n",
      "Epochs 79/1000 - Loss: 1.0381370782852173 - Metric: 0.5399009585380554\n",
      "----- 0.204s -----\n",
      "Epochs 80/1000 - Loss: 1.0375930070877075 - Metric: 0.539241373538971\n",
      "----- 0.201s -----\n",
      "Epochs 81/1000 - Loss: 1.037087082862854 - Metric: 0.5387156009674072\n",
      "----- 0.188s -----\n",
      "Epochs 82/1000 - Loss: 1.0366146564483643 - Metric: 0.538281261920929\n",
      "----- 0.185s -----\n",
      "Epochs 83/1000 - Loss: 1.0361602306365967 - Metric: 0.5379118919372559\n",
      "----- 0.19s -----\n",
      "Epochs 84/1000 - Loss: 1.0357309579849243 - Metric: 0.5376099944114685\n",
      "----- 0.198s -----\n",
      "Epochs 85/1000 - Loss: 1.035319209098816 - Metric: 0.5373271703720093\n",
      "----- 0.189s -----\n",
      "Epochs 86/1000 - Loss: 1.0349323749542236 - Metric: 0.5370318293571472\n",
      "----- 0.191s -----\n",
      "Epochs 87/1000 - Loss: 1.0345813035964966 - Metric: 0.5367335677146912\n",
      "----- 0.196s -----\n",
      "Epochs 88/1000 - Loss: 1.034246563911438 - Metric: 0.5364027619361877\n",
      "----- 0.189s -----\n",
      "Epochs 89/1000 - Loss: 1.033921480178833 - Metric: 0.5360274910926819\n",
      "----- 0.231s -----\n",
      "Epochs 90/1000 - Loss: 1.0336226224899292 - Metric: 0.5356554985046387\n",
      "----- 0.19s -----\n",
      "Epochs 91/1000 - Loss: 1.0333555936813354 - Metric: 0.5353337526321411\n",
      "----- 0.186s -----\n",
      "Epochs 92/1000 - Loss: 1.033108115196228 - Metric: 0.5350866913795471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.188s -----\n",
      "Epochs 93/1000 - Loss: 1.0328712463378906 - Metric: 0.5349100232124329\n",
      "----- 0.188s -----\n",
      "Epochs 94/1000 - Loss: 1.0326422452926636 - Metric: 0.5347416400909424\n",
      "----- 0.211s -----\n",
      "Epochs 95/1000 - Loss: 1.03242027759552 - Metric: 0.5345067381858826\n",
      "----- 0.197s -----\n",
      "Epochs 96/1000 - Loss: 1.0322051048278809 - Metric: 0.5341749787330627\n",
      "----- 0.192s -----\n",
      "Epochs 97/1000 - Loss: 1.031998872756958 - Metric: 0.5337818264961243\n",
      "----- 0.2s -----\n",
      "Epochs 98/1000 - Loss: 1.0318024158477783 - Metric: 0.5333898663520813\n",
      "----- 0.19s -----\n",
      "Epochs 99/1000 - Loss: 1.0316184759140015 - Metric: 0.5330122113227844\n",
      "----- 0.191s -----\n",
      "Epochs 100/1000 - Loss: 1.031445860862732 - Metric: 0.5326571464538574\n",
      "----- 0.209s -----\n",
      "Epochs 101/1000 - Loss: 1.0312823057174683 - Metric: 0.5323154330253601\n",
      "----- 0.189s -----\n",
      "Epochs 102/1000 - Loss: 1.0311274528503418 - Metric: 0.5319604277610779\n",
      "----- 0.189s -----\n",
      "Epochs 103/1000 - Loss: 1.0309791564941406 - Metric: 0.5316026210784912\n",
      "----- 0.196s -----\n",
      "Epochs 104/1000 - Loss: 1.0308363437652588 - Metric: 0.5312713980674744\n",
      "----- 0.188s -----\n",
      "Epochs 105/1000 - Loss: 1.0306997299194336 - Metric: 0.5309759974479675\n",
      "----- 0.205s -----\n",
      "Epochs 106/1000 - Loss: 1.03056800365448 - Metric: 0.5307234525680542\n",
      "----- 0.189s -----\n",
      "Epochs 107/1000 - Loss: 1.0304406881332397 - Metric: 0.530502438545227\n",
      "----- 0.191s -----\n",
      "Epochs 108/1000 - Loss: 1.030317783355713 - Metric: 0.5303009748458862\n",
      "----- 0.192s -----\n",
      "Epochs 109/1000 - Loss: 1.0302010774612427 - Metric: 0.5301257371902466\n",
      "----- 0.188s -----\n",
      "Epochs 110/1000 - Loss: 1.0300889015197754 - Metric: 0.5299829840660095\n",
      "----- 0.199s -----\n",
      "Epochs 111/1000 - Loss: 1.0299806594848633 - Metric: 0.5298622250556946\n",
      "----- 0.192s -----\n",
      "Epochs 112/1000 - Loss: 1.0298765897750854 - Metric: 0.5297529101371765\n",
      "----- 0.195s -----\n",
      "Epochs 113/1000 - Loss: 1.0297759771347046 - Metric: 0.5296375751495361\n",
      "----- 0.201s -----\n",
      "Epochs 114/1000 - Loss: 1.0296781063079834 - Metric: 0.5295247435569763\n",
      "----- 0.197s -----\n",
      "Epochs 115/1000 - Loss: 1.0295839309692383 - Metric: 0.5294193625450134\n",
      "----- 0.202s -----\n",
      "Epochs 116/1000 - Loss: 1.0294930934906006 - Metric: 0.5293066501617432\n",
      "----- 0.208s -----\n",
      "Epochs 117/1000 - Loss: 1.0294045209884644 - Metric: 0.5292307138442993\n",
      "----- 0.194s -----\n",
      "Epochs 118/1000 - Loss: 1.0293183326721191 - Metric: 0.5291418433189392\n",
      "----- 0.191s -----\n",
      "Epochs 119/1000 - Loss: 1.029234766960144 - Metric: 0.5290646553039551\n",
      "----- 0.196s -----\n",
      "Epochs 120/1000 - Loss: 1.0291543006896973 - Metric: 0.5289742946624756\n",
      "----- 0.202s -----\n",
      "Epochs 121/1000 - Loss: 1.029076099395752 - Metric: 0.5288659334182739\n",
      "----- 0.193s -----\n",
      "Epochs 122/1000 - Loss: 1.0289995670318604 - Metric: 0.5287732481956482\n",
      "----- 0.195s -----\n",
      "Epochs 123/1000 - Loss: 1.0289251804351807 - Metric: 0.528677761554718\n",
      "----- 0.196s -----\n",
      "Epochs 124/1000 - Loss: 1.028852939605713 - Metric: 0.5286039710044861\n",
      "----- 0.201s -----\n",
      "Epochs 125/1000 - Loss: 1.0287823677062988 - Metric: 0.5285325050354004\n",
      "----- 0.196s -----\n",
      "Epochs 126/1000 - Loss: 1.0287137031555176 - Metric: 0.5284419059753418\n",
      "----- 0.189s -----\n",
      "Epochs 127/1000 - Loss: 1.0286465883255005 - Metric: 0.5283703804016113\n",
      "----- 0.19s -----\n",
      "Epochs 128/1000 - Loss: 1.0285813808441162 - Metric: 0.5282779335975647\n",
      "----- 0.189s -----\n",
      "Epochs 129/1000 - Loss: 1.0285176038742065 - Metric: 0.5282140970230103\n",
      "----- 0.194s -----\n",
      "Epochs 130/1000 - Loss: 1.0284552574157715 - Metric: 0.5281520485877991\n",
      "----- 0.196s -----\n",
      "Epochs 131/1000 - Loss: 1.0283942222595215 - Metric: 0.528114914894104\n",
      "----- 0.176s -----\n",
      "Epochs 132/1000 - Loss: 1.028334140777588 - Metric: 0.5280652046203613\n",
      "----- 0.182s -----\n",
      "Epochs 133/1000 - Loss: 1.0282751321792603 - Metric: 0.5280376672744751\n",
      "----- 0.197s -----\n",
      "Epochs 134/1000 - Loss: 1.0282175540924072 - Metric: 0.5279791355133057\n",
      "----- 0.182s -----\n",
      "Epochs 135/1000 - Loss: 1.0281615257263184 - Metric: 0.5279483199119568\n",
      "----- 0.19s -----\n",
      "Epochs 136/1000 - Loss: 1.0281068086624146 - Metric: 0.5279020071029663\n",
      "----- 0.195s -----\n",
      "Epochs 137/1000 - Loss: 1.028052806854248 - Metric: 0.5278627872467041\n",
      "----- 0.182s -----\n",
      "Epochs 138/1000 - Loss: 1.027999758720398 - Metric: 0.5278279781341553\n",
      "----- 0.187s -----\n",
      "Epochs 139/1000 - Loss: 1.0279476642608643 - Metric: 0.527769923210144\n",
      "----- 0.194s -----\n",
      "Epochs 140/1000 - Loss: 1.0278971195220947 - Metric: 0.5277296900749207\n",
      "----- 0.187s -----\n",
      "Epochs 141/1000 - Loss: 1.0278475284576416 - Metric: 0.5276714563369751\n",
      "----- 0.199s -----\n",
      "Epochs 142/1000 - Loss: 1.0277986526489258 - Metric: 0.5276339054107666\n",
      "----- 0.187s -----\n",
      "Epochs 143/1000 - Loss: 1.0277502536773682 - Metric: 0.5275982618331909\n",
      "----- 0.189s -----\n",
      "Epochs 144/1000 - Loss: 1.027702808380127 - Metric: 0.5275610089302063\n",
      "----- 0.188s -----\n",
      "Epochs 145/1000 - Loss: 1.0276563167572021 - Metric: 0.5275326371192932\n",
      "----- 0.197s -----\n",
      "Epochs 146/1000 - Loss: 1.0276108980178833 - Metric: 0.527492105960846\n",
      "----- 0.199s -----\n",
      "Epochs 147/1000 - Loss: 1.0275659561157227 - Metric: 0.5274662971496582\n",
      "----- 0.192s -----\n",
      "Epochs 148/1000 - Loss: 1.0275217294692993 - Metric: 0.5274322032928467\n",
      "----- 0.19s -----\n",
      "Epochs 149/1000 - Loss: 1.0274782180786133 - Metric: 0.5274116396903992\n",
      "----- 0.19s -----\n",
      "Epochs 150/1000 - Loss: 1.027435541152954 - Metric: 0.5273901224136353\n",
      "----- 0.189s -----\n",
      "Epochs 151/1000 - Loss: 1.0273935794830322 - Metric: 0.5273687243461609\n",
      "----- 0.194s -----\n",
      "Epochs 152/1000 - Loss: 1.027352213859558 - Metric: 0.5273500680923462\n",
      "----- 0.191s -----\n",
      "Epochs 153/1000 - Loss: 1.0273113250732422 - Metric: 0.5273244380950928\n",
      "----- 0.186s -----\n",
      "Epochs 154/1000 - Loss: 1.0272711515426636 - Metric: 0.527306318283081\n",
      "----- 0.197s -----\n",
      "Epochs 155/1000 - Loss: 1.0272314548492432 - Metric: 0.5272839665412903\n",
      "----- 0.203s -----\n",
      "Epochs 156/1000 - Loss: 1.02719247341156 - Metric: 0.5272680521011353\n",
      "----- 0.198s -----\n",
      "Epochs 157/1000 - Loss: 1.0271540880203247 - Metric: 0.527250349521637\n",
      "----- 0.191s -----\n",
      "Epochs 158/1000 - Loss: 1.027116060256958 - Metric: 0.5272340774536133\n",
      "----- 0.193s -----\n",
      "Epochs 159/1000 - Loss: 1.027078628540039 - Metric: 0.5272160172462463\n",
      "----- 0.188s -----\n",
      "Epochs 160/1000 - Loss: 1.0270416736602783 - Metric: 0.5271971225738525\n",
      "----- 0.193s -----\n",
      "Epochs 161/1000 - Loss: 1.0270053148269653 - Metric: 0.5271784067153931\n",
      "----- 0.201s -----\n",
      "Epochs 162/1000 - Loss: 1.0269694328308105 - Metric: 0.5271549224853516\n",
      "----- 0.197s -----\n",
      "Epochs 163/1000 - Loss: 1.0269339084625244 - Metric: 0.5271396636962891\n",
      "----- 0.183s -----\n",
      "Epochs 164/1000 - Loss: 1.026898980140686 - Metric: 0.527120053768158\n",
      "----- 0.187s -----\n",
      "Epochs 165/1000 - Loss: 1.0268642902374268 - Metric: 0.5271032452583313\n",
      "----- 0.195s -----\n",
      "Epochs 166/1000 - Loss: 1.0268301963806152 - Metric: 0.5270816683769226\n",
      "----- 0.195s -----\n",
      "Epochs 167/1000 - Loss: 1.0267964601516724 - Metric: 0.5270633101463318\n",
      "----- 0.193s -----\n",
      "Epochs 168/1000 - Loss: 1.0267632007598877 - Metric: 0.5270443558692932\n",
      "----- 0.189s -----\n",
      "Epochs 169/1000 - Loss: 1.0267301797866821 - Metric: 0.5270312428474426\n",
      "----- 0.186s -----\n",
      "Epochs 170/1000 - Loss: 1.0266976356506348 - Metric: 0.5270109176635742\n",
      "----- 0.196s -----\n",
      "Epochs 171/1000 - Loss: 1.0266655683517456 - Metric: 0.5269976258277893\n",
      "----- 0.2s -----\n",
      "Epochs 172/1000 - Loss: 1.0266337394714355 - Metric: 0.5269759297370911\n",
      "----- 0.191s -----\n",
      "Epochs 173/1000 - Loss: 1.0266022682189941 - Metric: 0.5269584059715271\n",
      "----- 0.19s -----\n",
      "Epochs 174/1000 - Loss: 1.0265710353851318 - Metric: 0.5269428491592407\n",
      "----- 0.192s -----\n",
      "Epochs 175/1000 - Loss: 1.0265402793884277 - Metric: 0.526917576789856\n",
      "----- 0.195s -----\n",
      "Epochs 176/1000 - Loss: 1.0265100002288818 - Metric: 0.5269115567207336\n",
      "----- 0.192s -----\n",
      "Epochs 177/1000 - Loss: 1.0264800786972046 - Metric: 0.5268892645835876\n",
      "----- 0.195s -----\n",
      "Epochs 178/1000 - Loss: 1.0264503955841064 - Metric: 0.526885986328125\n",
      "----- 0.189s -----\n",
      "Epochs 179/1000 - Loss: 1.026421070098877 - Metric: 0.5268667936325073\n",
      "----- 0.186s -----\n",
      "Epochs 180/1000 - Loss: 1.0263922214508057 - Metric: 0.5268614292144775\n",
      "----- 0.186s -----\n",
      "Epochs 181/1000 - Loss: 1.026363730430603 - Metric: 0.5268447995185852\n",
      "----- 0.186s -----\n",
      "Epochs 182/1000 - Loss: 1.0263354778289795 - Metric: 0.5268427729606628\n",
      "----- 0.199s -----\n",
      "Epochs 183/1000 - Loss: 1.0263075828552246 - Metric: 0.5268275141716003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.184s -----\n",
      "Epochs 184/1000 - Loss: 1.0262800455093384 - Metric: 0.5268199443817139\n",
      "----- 0.184s -----\n",
      "Epochs 185/1000 - Loss: 1.0262528657913208 - Metric: 0.5267968773841858\n",
      "----- 0.192s -----\n",
      "Epochs 186/1000 - Loss: 1.0262258052825928 - Metric: 0.5267962217330933\n",
      "----- 0.189s -----\n",
      "Epochs 187/1000 - Loss: 1.026199460029602 - Metric: 0.5267763733863831\n",
      "----- 0.197s -----\n",
      "Epochs 188/1000 - Loss: 1.0261731147766113 - Metric: 0.5267740488052368\n",
      "----- 0.192s -----\n",
      "Epochs 189/1000 - Loss: 1.0261471271514893 - Metric: 0.5267574191093445\n",
      "----- 0.197s -----\n",
      "Epochs 190/1000 - Loss: 1.0261214971542358 - Metric: 0.5267529487609863\n",
      "----- 0.191s -----\n",
      "Epochs 191/1000 - Loss: 1.0260961055755615 - Metric: 0.5267408490180969\n",
      "----- 0.193s -----\n",
      "Epochs 192/1000 - Loss: 1.0260710716247559 - Metric: 0.5267336964607239\n",
      "----- 0.201s -----\n",
      "Epochs 193/1000 - Loss: 1.0260462760925293 - Metric: 0.5267220139503479\n",
      "----- 0.19s -----\n",
      "Epochs 194/1000 - Loss: 1.0260217189788818 - Metric: 0.5267083048820496\n",
      "----- 0.191s -----\n",
      "Epochs 195/1000 - Loss: 1.025997519493103 - Metric: 0.5267034769058228\n",
      "----- 0.185s -----\n",
      "Epochs 196/1000 - Loss: 1.0259734392166138 - Metric: 0.5266789197921753\n",
      "----- 0.196s -----\n",
      "Epochs 197/1000 - Loss: 1.0259497165679932 - Metric: 0.5266798138618469\n",
      "----- 0.183s -----\n",
      "Epochs 198/1000 - Loss: 1.0259262323379517 - Metric: 0.5266662836074829\n",
      "----- 0.197s -----\n",
      "Epochs 199/1000 - Loss: 1.0259029865264893 - Metric: 0.5266643762588501\n",
      "----- 0.211s -----\n",
      "Epochs 200/1000 - Loss: 1.0258798599243164 - Metric: 0.526648223400116\n",
      "----- 0.188s -----\n",
      "Epochs 201/1000 - Loss: 1.0258570909500122 - Metric: 0.5266417264938354\n",
      "----- 0.195s -----\n",
      "Epochs 202/1000 - Loss: 1.0258344411849976 - Metric: 0.5266295671463013\n",
      "----- 0.201s -----\n",
      "Epochs 203/1000 - Loss: 1.025812029838562 - Metric: 0.5266286134719849\n",
      "----- 0.191s -----\n",
      "Epochs 204/1000 - Loss: 1.0257898569107056 - Metric: 0.5266103744506836\n",
      "----- 0.191s -----\n",
      "Epochs 205/1000 - Loss: 1.0257678031921387 - Metric: 0.5266073942184448\n",
      "----- 0.192s -----\n",
      "Epochs 206/1000 - Loss: 1.0257459878921509 - Metric: 0.5265915989875793\n",
      "----- 0.193s -----\n",
      "Epochs 207/1000 - Loss: 1.0257244110107422 - Metric: 0.5265909433364868\n",
      "----- 0.198s -----\n",
      "Epochs 208/1000 - Loss: 1.025702714920044 - Metric: 0.5265769362449646\n",
      "----- 0.184s -----\n",
      "Epochs 209/1000 - Loss: 1.0256816148757935 - Metric: 0.5265770554542542\n",
      "----- 0.186s -----\n",
      "Epochs 210/1000 - Loss: 1.025660514831543 - Metric: 0.5265564322471619\n",
      "----- 0.185s -----\n",
      "Epochs 211/1000 - Loss: 1.025639533996582 - Metric: 0.5265561938285828\n",
      "----- 0.198s -----\n",
      "Epochs 212/1000 - Loss: 1.0256187915802002 - Metric: 0.5265374779701233\n",
      "----- 0.2s -----\n",
      "Epochs 213/1000 - Loss: 1.025598168373108 - Metric: 0.5265415906906128\n",
      "----- 0.197s -----\n",
      "Epochs 214/1000 - Loss: 1.0255776643753052 - Metric: 0.5265295505523682\n",
      "----- 0.191s -----\n",
      "Epochs 215/1000 - Loss: 1.0255573987960815 - Metric: 0.526523768901825\n",
      "----- 0.185s -----\n",
      "Epochs 216/1000 - Loss: 1.0255372524261475 - Metric: 0.5265025496482849\n",
      "----- 0.184s -----\n",
      "Epochs 217/1000 - Loss: 1.025517225265503 - Metric: 0.5265100598335266\n",
      "----- 0.188s -----\n",
      "Epochs 218/1000 - Loss: 1.025497555732727 - Metric: 0.5264942049980164\n",
      "----- 0.196s -----\n",
      "Epochs 219/1000 - Loss: 1.0254778861999512 - Metric: 0.5264977812767029\n",
      "----- 0.184s -----\n",
      "Epochs 220/1000 - Loss: 1.025458574295044 - Metric: 0.5264732241630554\n",
      "----- 0.183s -----\n",
      "Epochs 221/1000 - Loss: 1.0254392623901367 - Metric: 0.5264809727668762\n",
      "----- 0.187s -----\n",
      "Epochs 222/1000 - Loss: 1.025420069694519 - Metric: 0.5264558792114258\n",
      "----- 0.197s -----\n",
      "Epochs 223/1000 - Loss: 1.0254011154174805 - Metric: 0.5264769792556763\n",
      "----- 0.197s -----\n",
      "Epochs 224/1000 - Loss: 1.0253822803497314 - Metric: 0.5264436602592468\n",
      "----- 0.19s -----\n",
      "Epochs 225/1000 - Loss: 1.0253636837005615 - Metric: 0.526465892791748\n",
      "----- 0.191s -----\n",
      "Epochs 226/1000 - Loss: 1.0253452062606812 - Metric: 0.5264168977737427\n",
      "----- 0.192s -----\n",
      "Epochs 227/1000 - Loss: 1.0253268480300903 - Metric: 0.5264630913734436\n",
      "----- 0.191s -----\n",
      "Epochs 228/1000 - Loss: 1.0253088474273682 - Metric: 0.5264059901237488\n",
      "----- 0.204s -----\n",
      "Epochs 229/1000 - Loss: 1.025291085243225 - Metric: 0.5264682769775391\n",
      "----- 0.19s -----\n",
      "Epochs 230/1000 - Loss: 1.0252735614776611 - Metric: 0.5263773202896118\n",
      "----- 0.193s -----\n",
      "Epochs 231/1000 - Loss: 1.0252561569213867 - Metric: 0.526461124420166\n",
      "----- 0.191s -----\n",
      "Epochs 232/1000 - Loss: 1.0252389907836914 - Metric: 0.526354193687439\n",
      "----- 0.196s -----\n",
      "Epochs 233/1000 - Loss: 1.0252220630645752 - Metric: 0.5264777541160583\n",
      "----- 0.202s -----\n",
      "Epochs 234/1000 - Loss: 1.025205135345459 - Metric: 0.5263358354568481\n",
      "----- 0.19s -----\n",
      "Epochs 235/1000 - Loss: 1.0251880884170532 - Metric: 0.526475191116333\n",
      "----- 0.193s -----\n",
      "Epochs 236/1000 - Loss: 1.0251710414886475 - Metric: 0.5263098478317261\n",
      "----- 0.199s -----\n",
      "Epochs 237/1000 - Loss: 1.025153636932373 - Metric: 0.5264624953269958\n",
      "----- 0.19s -----\n",
      "Epochs 238/1000 - Loss: 1.0251359939575195 - Metric: 0.5263119339942932\n",
      "----- 0.202s -----\n",
      "Epochs 239/1000 - Loss: 1.025118112564087 - Metric: 0.5264388918876648\n",
      "----- 0.194s -----\n",
      "Epochs 240/1000 - Loss: 1.0251003503799438 - Metric: 0.5263306498527527\n",
      "----- 0.191s -----\n",
      "Epochs 241/1000 - Loss: 1.025083065032959 - Metric: 0.526398241519928\n",
      "----- 0.189s -----\n",
      "Epochs 242/1000 - Loss: 1.0250661373138428 - Metric: 0.5263514518737793\n",
      "----- 0.205s -----\n",
      "Epochs 243/1000 - Loss: 1.0250496864318848 - Metric: 0.5263559818267822\n",
      "----- 0.206s -----\n",
      "Epochs 244/1000 - Loss: 1.025033712387085 - Metric: 0.5263738632202148\n",
      "----- 0.191s -----\n",
      "Epochs 245/1000 - Loss: 1.0250178575515747 - Metric: 0.5263271927833557\n",
      "----- 0.189s -----\n",
      "Epochs 246/1000 - Loss: 1.025002360343933 - Metric: 0.5263876914978027\n",
      "----- 0.185s -----\n",
      "Epochs 247/1000 - Loss: 1.0249866247177124 - Metric: 0.5263057351112366\n",
      "----- 0.197s -----\n",
      "Epochs 248/1000 - Loss: 1.0249711275100708 - Metric: 0.5263918042182922\n",
      "----- 0.203s -----\n",
      "Epochs 249/1000 - Loss: 1.02495539188385 - Metric: 0.5262993574142456\n",
      "----- 0.201s -----\n",
      "Epochs 250/1000 - Loss: 1.024939775466919 - Metric: 0.5263805389404297\n",
      "----- 0.195s -----\n",
      "Epochs 251/1000 - Loss: 1.0249241590499878 - Metric: 0.5262969732284546\n",
      "----- 0.194s -----\n",
      "Epochs 252/1000 - Loss: 1.0249087810516357 - Metric: 0.5263672471046448\n",
      "----- 0.199s -----\n",
      "Epochs 253/1000 - Loss: 1.0248932838439941 - Metric: 0.5263088941574097\n",
      "----- 0.232s -----\n",
      "Epochs 254/1000 - Loss: 1.0248780250549316 - Metric: 0.5263471603393555\n",
      "----- 0.225s -----\n",
      "Epochs 255/1000 - Loss: 1.0248630046844482 - Metric: 0.5263170599937439\n",
      "----- 0.192s -----\n",
      "Epochs 256/1000 - Loss: 1.0248481035232544 - Metric: 0.5263327956199646\n",
      "----- 0.201s -----\n",
      "Epochs 257/1000 - Loss: 1.0248334407806396 - Metric: 0.5263260006904602\n",
      "----- 0.203s -----\n",
      "Epochs 258/1000 - Loss: 1.024818778038025 - Metric: 0.5263135433197021\n",
      "----- 0.205s -----\n",
      "Epochs 259/1000 - Loss: 1.0248041152954102 - Metric: 0.5263320207595825\n",
      "----- 0.199s -----\n",
      "Epochs 260/1000 - Loss: 1.0247899293899536 - Metric: 0.526309609413147\n",
      "----- 0.198s -----\n",
      "Epochs 261/1000 - Loss: 1.024775505065918 - Metric: 0.5263392329216003\n",
      "----- 0.197s -----\n",
      "Epochs 262/1000 - Loss: 1.0247615575790405 - Metric: 0.5262970924377441\n",
      "----- 0.207s -----\n",
      "Epochs 263/1000 - Loss: 1.024747371673584 - Metric: 0.5263383984565735\n",
      "----- 0.206s -----\n",
      "Epochs 264/1000 - Loss: 1.0247334241867065 - Metric: 0.526294469833374\n",
      "----- 0.203s -----\n",
      "Epochs 265/1000 - Loss: 1.0247195959091187 - Metric: 0.5263422727584839\n",
      "----- 0.198s -----\n",
      "Epochs 266/1000 - Loss: 1.0247058868408203 - Metric: 0.5262873768806458\n",
      "----- 0.199s -----\n",
      "Epochs 267/1000 - Loss: 1.0246922969818115 - Metric: 0.5263441205024719\n",
      "----- 0.203s -----\n",
      "Epochs 268/1000 - Loss: 1.0246787071228027 - Metric: 0.5262834429740906\n",
      "----- 0.212s -----\n",
      "Epochs 269/1000 - Loss: 1.024665117263794 - Metric: 0.5263465046882629\n",
      "----- 0.192s -----\n",
      "Epochs 270/1000 - Loss: 1.0246520042419434 - Metric: 0.5262771248817444\n",
      "----- 0.216s -----\n",
      "Epochs 271/1000 - Loss: 1.0246386528015137 - Metric: 0.5263510942459106\n",
      "----- 0.191s -----\n",
      "Epochs 272/1000 - Loss: 1.0246256589889526 - Metric: 0.5262730717658997\n",
      "----- 0.196s -----\n",
      "Epochs 273/1000 - Loss: 1.0246126651763916 - Metric: 0.5263592004776001\n",
      "----- 0.192s -----\n",
      "Epochs 274/1000 - Loss: 1.0245997905731201 - Metric: 0.5262665152549744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.194s -----\n",
      "Epochs 275/1000 - Loss: 1.0245871543884277 - Metric: 0.5263667702674866\n",
      "----- 0.208s -----\n",
      "Epochs 276/1000 - Loss: 1.024574637413025 - Metric: 0.5262563228607178\n",
      "----- 0.19s -----\n",
      "Epochs 277/1000 - Loss: 1.024562120437622 - Metric: 0.526375949382782\n",
      "----- 0.199s -----\n",
      "Epochs 278/1000 - Loss: 1.024549961090088 - Metric: 0.5262482166290283\n",
      "----- 0.195s -----\n",
      "Epochs 279/1000 - Loss: 1.0245376825332642 - Metric: 0.526390552520752\n",
      "----- 0.19s -----\n",
      "Epochs 280/1000 - Loss: 1.024525761604309 - Metric: 0.5262379050254822\n",
      "----- 0.194s -----\n",
      "Epochs 281/1000 - Loss: 1.0245137214660645 - Metric: 0.5263991951942444\n",
      "----- 0.188s -----\n",
      "Epochs 282/1000 - Loss: 1.0245018005371094 - Metric: 0.5262338519096375\n",
      "----- 0.182s -----\n",
      "Epochs 283/1000 - Loss: 1.024489402770996 - Metric: 0.5264057517051697\n",
      "----- 0.194s -----\n",
      "Epochs 284/1000 - Loss: 1.024477243423462 - Metric: 0.5262370109558105\n",
      "----- 0.194s -----\n",
      "Epochs 285/1000 - Loss: 1.0244649648666382 - Metric: 0.5264073014259338\n",
      "----- 0.2s -----\n",
      "Epochs 286/1000 - Loss: 1.0244524478912354 - Metric: 0.5262477993965149\n",
      "----- 0.193s -----\n",
      "Epochs 287/1000 - Loss: 1.0244399309158325 - Metric: 0.5263879895210266\n",
      "----- 0.19s -----\n",
      "Epochs 288/1000 - Loss: 1.0244276523590088 - Metric: 0.5262605547904968\n",
      "----- 0.217s -----\n",
      "Epochs 289/1000 - Loss: 1.024415373802185 - Metric: 0.5263702273368835\n",
      "----- 0.204s -----\n",
      "Epochs 290/1000 - Loss: 1.0244030952453613 - Metric: 0.5262905955314636\n",
      "----- 0.189s -----\n",
      "Epochs 291/1000 - Loss: 1.024391531944275 - Metric: 0.526350200176239\n",
      "----- 0.193s -----\n",
      "Epochs 292/1000 - Loss: 1.0243797302246094 - Metric: 0.5263057351112366\n",
      "----- 0.189s -----\n",
      "Epochs 293/1000 - Loss: 1.024368405342102 - Metric: 0.5263237357139587\n",
      "----- 0.197s -----\n",
      "Epochs 294/1000 - Loss: 1.0243570804595947 - Metric: 0.5263285040855408\n",
      "----- 0.196s -----\n",
      "Epochs 295/1000 - Loss: 1.0243459939956665 - Metric: 0.5263209939002991\n",
      "----- 0.185s -----\n",
      "Epochs 296/1000 - Loss: 1.0243349075317383 - Metric: 0.5263487100601196\n",
      "----- 0.201s -----\n",
      "Epochs 297/1000 - Loss: 1.0243240594863892 - Metric: 0.5263060331344604\n",
      "----- 0.223s -----\n",
      "Epochs 298/1000 - Loss: 1.02431321144104 - Metric: 0.52635258436203\n",
      "----- 0.202s -----\n",
      "Epochs 299/1000 - Loss: 1.0243024826049805 - Metric: 0.5262982249259949\n",
      "----- 0.211s -----\n",
      "Epochs 300/1000 - Loss: 1.024291753768921 - Metric: 0.5263670682907104\n",
      "----- 0.189s -----\n",
      "Epochs 301/1000 - Loss: 1.0242812633514404 - Metric: 0.5262918472290039\n",
      "----- 0.191s -----\n",
      "Epochs 302/1000 - Loss: 1.0242708921432495 - Metric: 0.5263761281967163\n",
      "----- 0.223s -----\n",
      "Epochs 303/1000 - Loss: 1.0242605209350586 - Metric: 0.5262876749038696\n",
      "----- 0.212s -----\n",
      "Epochs 304/1000 - Loss: 1.0242502689361572 - Metric: 0.5263926982879639\n",
      "----- 0.196s -----\n",
      "Epochs 305/1000 - Loss: 1.0242400169372559 - Metric: 0.526284396648407\n",
      "----- 0.193s -----\n",
      "Epochs 306/1000 - Loss: 1.024229884147644 - Metric: 0.5263975858688354\n",
      "----- 0.222s -----\n",
      "Epochs 307/1000 - Loss: 1.0242197513580322 - Metric: 0.5262764096260071\n",
      "----- 0.241s -----\n",
      "Epochs 308/1000 - Loss: 1.0242098569869995 - Metric: 0.5264079570770264\n",
      "----- 0.202s -----\n",
      "Epochs 309/1000 - Loss: 1.0241999626159668 - Metric: 0.5262764692306519\n",
      "----- 0.209s -----\n",
      "Epochs 310/1000 - Loss: 1.0241899490356445 - Metric: 0.5264193415641785\n",
      "----- 0.193s -----\n",
      "Epochs 311/1000 - Loss: 1.024180293083191 - Metric: 0.5262762904167175\n",
      "----- 0.196s -----\n",
      "Epochs 312/1000 - Loss: 1.0241705179214478 - Metric: 0.5264255404472351\n",
      "----- 0.225s -----\n",
      "Epochs 313/1000 - Loss: 1.0241608619689941 - Metric: 0.5262722969055176\n",
      "----- 0.187s -----\n",
      "Epochs 314/1000 - Loss: 1.0241512060165405 - Metric: 0.5264256596565247\n",
      "----- 0.192s -----\n",
      "Epochs 315/1000 - Loss: 1.0241414308547974 - Metric: 0.5262784957885742\n",
      "----- 0.219s -----\n",
      "Epochs 316/1000 - Loss: 1.0241317749023438 - Metric: 0.5264275670051575\n",
      "----- 0.19s -----\n",
      "Epochs 317/1000 - Loss: 1.024121880531311 - Metric: 0.5262874960899353\n",
      "----- 0.202s -----\n",
      "Epochs 318/1000 - Loss: 1.0241119861602783 - Metric: 0.5264243483543396\n",
      "----- 0.192s -----\n",
      "Epochs 319/1000 - Loss: 1.0241024494171143 - Metric: 0.5263000726699829\n",
      "----- 0.21s -----\n",
      "Epochs 320/1000 - Loss: 1.024092674255371 - Metric: 0.5264105200767517\n",
      "----- 0.189s -----\n",
      "Epochs 321/1000 - Loss: 1.0240832567214966 - Metric: 0.5263071656227112\n",
      "----- 0.193s -----\n",
      "Epochs 322/1000 - Loss: 1.024073839187622 - Metric: 0.5264014601707458\n",
      "----- 0.223s -----\n",
      "Epochs 323/1000 - Loss: 1.024064540863037 - Metric: 0.5263303518295288\n",
      "----- 0.191s -----\n",
      "Epochs 324/1000 - Loss: 1.0240553617477417 - Metric: 0.5264009833335876\n",
      "----- 0.188s -----\n",
      "Epochs 325/1000 - Loss: 1.0240461826324463 - Metric: 0.5263403058052063\n",
      "----- 0.197s -----\n",
      "Epochs 326/1000 - Loss: 1.0240373611450195 - Metric: 0.5263913869857788\n",
      "----- 0.213s -----\n",
      "Epochs 327/1000 - Loss: 1.0240283012390137 - Metric: 0.5263513922691345\n",
      "----- 0.206s -----\n",
      "Epochs 328/1000 - Loss: 1.024019479751587 - Metric: 0.5263901352882385\n",
      "----- 0.19s -----\n",
      "Epochs 329/1000 - Loss: 1.0240107774734497 - Metric: 0.5263510942459106\n",
      "----- 0.192s -----\n",
      "Epochs 330/1000 - Loss: 1.0240020751953125 - Metric: 0.5263895988464355\n",
      "----- 0.211s -----\n",
      "Epochs 331/1000 - Loss: 1.0239934921264648 - Metric: 0.5263624787330627\n",
      "----- 0.198s -----\n",
      "Epochs 332/1000 - Loss: 1.0239850282669067 - Metric: 0.5264076590538025\n",
      "----- 0.208s -----\n",
      "Epochs 333/1000 - Loss: 1.0239763259887695 - Metric: 0.5263639688491821\n",
      "----- 0.188s -----\n",
      "Epochs 334/1000 - Loss: 1.02396821975708 - Metric: 0.5264047980308533\n",
      "----- 0.297s -----\n",
      "Epochs 335/1000 - Loss: 1.0239598751068115 - Metric: 0.5263551473617554\n",
      "----- 0.235s -----\n",
      "Epochs 336/1000 - Loss: 1.023951768875122 - Metric: 0.5264226794242859\n",
      "----- 0.229s -----\n",
      "Epochs 337/1000 - Loss: 1.0239437818527222 - Metric: 0.5263535976409912\n",
      "----- 0.193s -----\n",
      "Epochs 338/1000 - Loss: 1.0239360332489014 - Metric: 0.5264412760734558\n",
      "----- 0.193s -----\n",
      "Epochs 339/1000 - Loss: 1.023928165435791 - Metric: 0.5263431668281555\n",
      "----- 0.193s -----\n",
      "Epochs 340/1000 - Loss: 1.0239207744598389 - Metric: 0.5264645218849182\n",
      "----- 0.19s -----\n",
      "Epochs 341/1000 - Loss: 1.0239133834838867 - Metric: 0.5263233780860901\n",
      "----- 0.2s -----\n",
      "Epochs 342/1000 - Loss: 1.0239065885543823 - Metric: 0.5264884829521179\n",
      "----- 0.191s -----\n",
      "Epochs 343/1000 - Loss: 1.023899793624878 - Metric: 0.526307225227356\n",
      "----- 0.187s -----\n",
      "Epochs 344/1000 - Loss: 1.0238933563232422 - Metric: 0.5265307426452637\n",
      "----- 0.188s -----\n",
      "Epochs 345/1000 - Loss: 1.0238869190216064 - Metric: 0.5262900590896606\n",
      "----- 0.207s -----\n",
      "Epochs 346/1000 - Loss: 1.0238807201385498 - Metric: 0.5265579223632812\n",
      "----- 0.226s -----\n",
      "Epochs 347/1000 - Loss: 1.0238738059997559 - Metric: 0.526281476020813\n",
      "----- 0.191s -----\n",
      "Epochs 348/1000 - Loss: 1.0238664150238037 - Metric: 0.5265749096870422\n",
      "----- 0.188s -----\n",
      "Epochs 349/1000 - Loss: 1.023857831954956 - Metric: 0.5262914299964905\n",
      "----- 0.215s -----\n",
      "Epochs 350/1000 - Loss: 1.0238487720489502 - Metric: 0.52655428647995\n",
      "----- 0.181s -----\n",
      "Epochs 351/1000 - Loss: 1.023838996887207 - Metric: 0.5263324975967407\n",
      "----- 0.195s -----\n",
      "Epochs 352/1000 - Loss: 1.0238295793533325 - Metric: 0.5265153646469116\n",
      "----- 0.202s -----\n",
      "Epochs 353/1000 - Loss: 1.0238207578659058 - Metric: 0.5263967514038086\n",
      "----- 0.19s -----\n",
      "Epochs 354/1000 - Loss: 1.0238127708435059 - Metric: 0.5264555215835571\n",
      "----- 0.19s -----\n",
      "Epochs 355/1000 - Loss: 1.0238056182861328 - Metric: 0.526459813117981\n",
      "----- 0.28s -----\n",
      "Epochs 356/1000 - Loss: 1.023799180984497 - Metric: 0.5264100432395935\n",
      "----- 0.197s -----\n",
      "Epochs 357/1000 - Loss: 1.0237932205200195 - Metric: 0.5265145301818848\n",
      "----- 0.211s -----\n",
      "Epochs 358/1000 - Loss: 1.0237871408462524 - Metric: 0.5263766646385193\n",
      "----- 0.19s -----\n",
      "Epochs 359/1000 - Loss: 1.0237810611724854 - Metric: 0.5265449285507202\n",
      "----- 0.192s -----\n",
      "Epochs 360/1000 - Loss: 1.02377450466156 - Metric: 0.5263708829879761\n",
      "----- 0.193s -----\n",
      "Epochs 361/1000 - Loss: 1.0237677097320557 - Metric: 0.5265557765960693\n",
      "----- 0.204s -----\n",
      "Epochs 362/1000 - Loss: 1.0237603187561035 - Metric: 0.5263884663581848\n",
      "----- 0.19s -----\n",
      "Epochs 363/1000 - Loss: 1.023753046989441 - Metric: 0.526538074016571\n",
      "----- 0.184s -----\n",
      "Epochs 364/1000 - Loss: 1.0237455368041992 - Metric: 0.5264201760292053\n",
      "----- 0.206s -----\n",
      "Epochs 365/1000 - Loss: 1.0237385034561157 - Metric: 0.5265116095542908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.191s -----\n",
      "Epochs 366/1000 - Loss: 1.0237317085266113 - Metric: 0.5264619588851929\n",
      "----- 0.245s -----\n",
      "Epochs 367/1000 - Loss: 1.0237252712249756 - Metric: 0.5264819860458374\n",
      "----- 0.19s -----\n",
      "Epochs 368/1000 - Loss: 1.0237191915512085 - Metric: 0.5264970660209656\n",
      "----- 0.215s -----\n",
      "Epochs 369/1000 - Loss: 1.0237131118774414 - Metric: 0.5264584422111511\n",
      "----- 0.196s -----\n",
      "Epochs 370/1000 - Loss: 1.0237075090408325 - Metric: 0.5265330672264099\n",
      "----- 0.227s -----\n",
      "Epochs 371/1000 - Loss: 1.023701786994934 - Metric: 0.5264500975608826\n",
      "----- 0.193s -----\n",
      "Epochs 372/1000 - Loss: 1.0236960649490356 - Metric: 0.5265543460845947\n",
      "----- 0.215s -----\n",
      "Epochs 373/1000 - Loss: 1.0236903429031372 - Metric: 0.5264464616775513\n",
      "----- 0.185s -----\n",
      "Epochs 374/1000 - Loss: 1.0236845016479492 - Metric: 0.5265623927116394\n",
      "----- 0.22s -----\n",
      "Epochs 375/1000 - Loss: 1.0236785411834717 - Metric: 0.5264649391174316\n",
      "----- 0.196s -----\n",
      "Epochs 376/1000 - Loss: 1.0236726999282837 - Metric: 0.5265704393386841\n",
      "----- 0.194s -----\n",
      "Epochs 377/1000 - Loss: 1.0236668586730957 - Metric: 0.5264832973480225\n",
      "----- 0.213s -----\n",
      "Epochs 378/1000 - Loss: 1.0236610174179077 - Metric: 0.5265608429908752\n",
      "----- 0.19s -----\n",
      "Epochs 379/1000 - Loss: 1.0236554145812988 - Metric: 0.5265036821365356\n",
      "----- 0.21s -----\n",
      "Epochs 380/1000 - Loss: 1.0236499309539795 - Metric: 0.5265511274337769\n",
      "----- 0.209s -----\n",
      "Epochs 381/1000 - Loss: 1.0236444473266602 - Metric: 0.5265308618545532\n",
      "----- 0.188s -----\n",
      "Epochs 382/1000 - Loss: 1.0236390829086304 - Metric: 0.5265508890151978\n",
      "----- 0.201s -----\n",
      "Epochs 383/1000 - Loss: 1.0236338376998901 - Metric: 0.5265489220619202\n",
      "----- 0.19s -----\n",
      "Epochs 384/1000 - Loss: 1.0236287117004395 - Metric: 0.5265493988990784\n",
      "----- 0.191s -----\n",
      "Epochs 385/1000 - Loss: 1.0236235857009888 - Metric: 0.5265659689903259\n",
      "----- 0.197s -----\n",
      "Epochs 386/1000 - Loss: 1.0236186981201172 - Metric: 0.5265516638755798\n",
      "----- 0.196s -----\n",
      "Epochs 387/1000 - Loss: 1.023613691329956 - Metric: 0.5265767574310303\n",
      "----- 0.21s -----\n",
      "Epochs 388/1000 - Loss: 1.023608684539795 - Metric: 0.5265518426895142\n",
      "----- 0.26s -----\n",
      "Epochs 389/1000 - Loss: 1.023603916168213 - Metric: 0.5265867114067078\n",
      "----- 0.22s -----\n",
      "Epochs 390/1000 - Loss: 1.0235991477966309 - Metric: 0.5265624523162842\n",
      "----- 0.203s -----\n",
      "Epochs 391/1000 - Loss: 1.0235944986343384 - Metric: 0.5265990495681763\n",
      "----- 0.196s -----\n",
      "Epochs 392/1000 - Loss: 1.0235896110534668 - Metric: 0.5265651345252991\n",
      "----- 0.19s -----\n",
      "Epochs 393/1000 - Loss: 1.0235850811004639 - Metric: 0.5266087055206299\n",
      "----- 0.208s -----\n",
      "Epochs 394/1000 - Loss: 1.0235804319381714 - Metric: 0.5265660285949707\n",
      "----- 0.201s -----\n",
      "Epochs 395/1000 - Loss: 1.023575782775879 - Metric: 0.5266215205192566\n",
      "----- 0.205s -----\n",
      "Epochs 396/1000 - Loss: 1.0235711336135864 - Metric: 0.5265755653381348\n",
      "----- 0.195s -----\n",
      "Epochs 397/1000 - Loss: 1.0235668420791626 - Metric: 0.5266371965408325\n",
      "----- 0.197s -----\n",
      "Epochs 398/1000 - Loss: 1.0235623121261597 - Metric: 0.5265743136405945\n",
      "----- 0.202s -----\n",
      "Epochs 399/1000 - Loss: 1.0235580205917358 - Metric: 0.5266419649124146\n",
      "----- 0.202s -----\n",
      "Epochs 400/1000 - Loss: 1.0235536098480225 - Metric: 0.5265705585479736\n",
      "----- 0.2s -----\n",
      "Epochs 401/1000 - Loss: 1.0235494375228882 - Metric: 0.5266627669334412\n",
      "----- 0.191s -----\n",
      "Epochs 402/1000 - Loss: 1.023545265197754 - Metric: 0.5265761613845825\n",
      "----- 0.187s -----\n",
      "Epochs 403/1000 - Loss: 1.0235410928726196 - Metric: 0.5266771912574768\n",
      "----- 0.201s -----\n",
      "Epochs 404/1000 - Loss: 1.0235369205474854 - Metric: 0.5265701413154602\n",
      "----- 0.199s -----\n",
      "Epochs 405/1000 - Loss: 1.0235331058502197 - Metric: 0.5266931653022766\n",
      "----- 0.193s -----\n",
      "Epochs 406/1000 - Loss: 1.0235294103622437 - Metric: 0.5265583992004395\n",
      "----- 0.189s -----\n",
      "Epochs 407/1000 - Loss: 1.0235258340835571 - Metric: 0.5267142057418823\n",
      "----- 0.199s -----\n",
      "Epochs 408/1000 - Loss: 1.023522138595581 - Metric: 0.5265557765960693\n",
      "----- 0.195s -----\n",
      "Epochs 409/1000 - Loss: 1.0235188007354736 - Metric: 0.5267437696456909\n",
      "----- 0.203s -----\n",
      "Epochs 410/1000 - Loss: 1.0235151052474976 - Metric: 0.5265541672706604\n",
      "----- 0.2s -----\n",
      "Epochs 411/1000 - Loss: 1.0235114097595215 - Metric: 0.5267675518989563\n",
      "----- 0.185s -----\n",
      "Epochs 412/1000 - Loss: 1.0235079526901245 - Metric: 0.5265514850616455\n",
      "----- 0.205s -----\n",
      "Epochs 413/1000 - Loss: 1.0235042572021484 - Metric: 0.5267816185951233\n",
      "----- 0.198s -----\n",
      "Epochs 414/1000 - Loss: 1.0235004425048828 - Metric: 0.5265477299690247\n",
      "----- 0.192s -----\n",
      "Epochs 415/1000 - Loss: 1.023496389389038 - Metric: 0.526785671710968\n",
      "----- 0.184s -----\n",
      "Epochs 416/1000 - Loss: 1.0234919786453247 - Metric: 0.5265678763389587\n",
      "----- 0.183s -----\n",
      "Epochs 417/1000 - Loss: 1.0234870910644531 - Metric: 0.5267788767814636\n",
      "----- 0.178s -----\n",
      "Epochs 418/1000 - Loss: 1.023482322692871 - Metric: 0.5265946984291077\n",
      "----- 0.184s -----\n",
      "Epochs 419/1000 - Loss: 1.0234774351119995 - Metric: 0.5267534255981445\n",
      "----- 0.187s -----\n",
      "Epochs 420/1000 - Loss: 1.023472785949707 - Metric: 0.5266310572624207\n",
      "----- 0.197s -----\n",
      "Epochs 421/1000 - Loss: 1.023468255996704 - Metric: 0.5267245173454285\n",
      "----- 0.217s -----\n",
      "Epochs 422/1000 - Loss: 1.0234642028808594 - Metric: 0.5266736149787903\n",
      "----- 0.182s -----\n",
      "Epochs 423/1000 - Loss: 1.0234603881835938 - Metric: 0.5267022252082825\n",
      "----- 0.19s -----\n",
      "Epochs 424/1000 - Loss: 1.0234568119049072 - Metric: 0.5267083048820496\n",
      "----- 0.185s -----\n",
      "Epochs 425/1000 - Loss: 1.0234533548355103 - Metric: 0.5266750454902649\n",
      "----- 0.198s -----\n",
      "Epochs 426/1000 - Loss: 1.0234500169754028 - Metric: 0.526725709438324\n",
      "----- 0.187s -----\n",
      "Epochs 427/1000 - Loss: 1.0234465599060059 - Metric: 0.5266674160957336\n",
      "----- 0.19s -----\n",
      "Epochs 428/1000 - Loss: 1.0234432220458984 - Metric: 0.5267558693885803\n",
      "----- 0.186s -----\n",
      "Epochs 429/1000 - Loss: 1.023439884185791 - Metric: 0.5266727805137634\n",
      "----- 0.185s -----\n",
      "Epochs 430/1000 - Loss: 1.0234365463256836 - Metric: 0.5267707109451294\n",
      "----- 0.197s -----\n",
      "Epochs 431/1000 - Loss: 1.0234332084655762 - Metric: 0.5266665816307068\n",
      "----- 0.184s -----\n",
      "Epochs 432/1000 - Loss: 1.0234297513961792 - Metric: 0.5267757773399353\n",
      "----- 0.187s -----\n",
      "Epochs 433/1000 - Loss: 1.0234265327453613 - Metric: 0.5266761779785156\n",
      "----- 0.189s -----\n",
      "Epochs 434/1000 - Loss: 1.023423194885254 - Metric: 0.5267899632453918\n",
      "----- 0.189s -----\n",
      "Epochs 435/1000 - Loss: 1.0234198570251465 - Metric: 0.5266857147216797\n",
      "----- 0.194s -----\n",
      "Epochs 436/1000 - Loss: 1.0234163999557495 - Metric: 0.526785671710968\n",
      "----- 0.188s -----\n",
      "Epochs 437/1000 - Loss: 1.023413062095642 - Metric: 0.5266901254653931\n",
      "----- 0.188s -----\n",
      "Epochs 438/1000 - Loss: 1.0234096050262451 - Metric: 0.5267894268035889\n",
      "----- 0.193s -----\n",
      "Epochs 439/1000 - Loss: 1.0234062671661377 - Metric: 0.5267093777656555\n",
      "----- 0.189s -----\n",
      "Epochs 440/1000 - Loss: 1.0234029293060303 - Metric: 0.5267916917800903\n",
      "----- 0.195s -----\n",
      "Epochs 441/1000 - Loss: 1.023399829864502 - Metric: 0.5267210006713867\n",
      "----- 0.174s -----\n",
      "Epochs 442/1000 - Loss: 1.0233964920043945 - Metric: 0.5267930626869202\n",
      "----- 0.185s -----\n",
      "Epochs 443/1000 - Loss: 1.0233933925628662 - Metric: 0.5267306566238403\n",
      "----- 0.205s -----\n",
      "Epochs 444/1000 - Loss: 1.0233900547027588 - Metric: 0.5267857909202576\n",
      "----- 0.18s -----\n",
      "Epochs 445/1000 - Loss: 1.0233871936798096 - Metric: 0.5267350673675537\n",
      "----- 0.195s -----\n",
      "Epochs 446/1000 - Loss: 1.0233839750289917 - Metric: 0.5267915725708008\n",
      "----- 0.192s -----\n",
      "Epochs 447/1000 - Loss: 1.023380994796753 - Metric: 0.526748538017273\n",
      "----- 0.184s -----\n",
      "Epochs 448/1000 - Loss: 1.0233778953552246 - Metric: 0.5267927646636963\n",
      "----- 0.185s -----\n",
      "Epochs 449/1000 - Loss: 1.0233749151229858 - Metric: 0.5267497897148132\n",
      "----- 0.181s -----\n",
      "Epochs 450/1000 - Loss: 1.0233720541000366 - Metric: 0.5267988443374634\n",
      "----- 0.184s -----\n",
      "Epochs 451/1000 - Loss: 1.0233690738677979 - Metric: 0.5267550945281982\n",
      "----- 0.206s -----\n",
      "Epochs 452/1000 - Loss: 1.0233662128448486 - Metric: 0.5268062353134155\n",
      "----- 0.184s -----\n",
      "Epochs 453/1000 - Loss: 1.023363471031189 - Metric: 0.5267540216445923\n",
      "----- 0.185s -----\n",
      "Epochs 454/1000 - Loss: 1.0233606100082397 - Metric: 0.5268169641494751\n",
      "----- 0.183s -----\n",
      "Epochs 455/1000 - Loss: 1.02335786819458 - Metric: 0.526752233505249\n",
      "----- 0.187s -----\n",
      "Epochs 456/1000 - Loss: 1.0233550071716309 - Metric: 0.5268245339393616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.199s -----\n",
      "Epochs 457/1000 - Loss: 1.0233526229858398 - Metric: 0.5267470479011536\n",
      "----- 0.182s -----\n",
      "Epochs 458/1000 - Loss: 1.0233498811721802 - Metric: 0.5268447399139404\n",
      "----- 0.182s -----\n",
      "Epochs 459/1000 - Loss: 1.0233474969863892 - Metric: 0.5267387628555298\n",
      "----- 0.201s -----\n",
      "Epochs 460/1000 - Loss: 1.0233452320098877 - Metric: 0.5268564224243164\n",
      "----- 0.185s -----\n",
      "Epochs 461/1000 - Loss: 1.0233428478240967 - Metric: 0.5267267823219299\n",
      "----- 0.185s -----\n",
      "Epochs 462/1000 - Loss: 1.0233409404754639 - Metric: 0.5268935561180115\n",
      "----- 0.184s -----\n",
      "Epochs 463/1000 - Loss: 1.0233391523361206 - Metric: 0.5267181992530823\n",
      "----- 0.194s -----\n",
      "Epochs 464/1000 - Loss: 1.0233376026153564 - Metric: 0.5269120335578918\n",
      "----- 0.177s -----\n",
      "Epochs 465/1000 - Loss: 1.0233360528945923 - Metric: 0.5266894698143005\n",
      "----- 0.186s -----\n",
      "Epochs 466/1000 - Loss: 1.0233345031738281 - Metric: 0.5269466042518616\n",
      "----- 0.188s -----\n",
      "Epochs 467/1000 - Loss: 1.0233330726623535 - Metric: 0.5266884565353394\n",
      "----- 0.182s -----\n",
      "Epochs 468/1000 - Loss: 1.0233314037322998 - Metric: 0.5269774794578552\n",
      "----- 0.181s -----\n",
      "Epochs 469/1000 - Loss: 1.023329257965088 - Metric: 0.5266810059547424\n",
      "----- 0.189s -----\n",
      "Epochs 470/1000 - Loss: 1.0233266353607178 - Metric: 0.5269838571548462\n",
      "----- 0.185s -----\n",
      "Epochs 471/1000 - Loss: 1.0233235359191895 - Metric: 0.5266865491867065\n",
      "----- 0.182s -----\n",
      "Epochs 472/1000 - Loss: 1.0233197212219238 - Metric: 0.5269642472267151\n",
      "----- 0.188s -----\n",
      "Epochs 473/1000 - Loss: 1.0233154296875 - Metric: 0.5267194509506226\n",
      "----- 0.185s -----\n",
      "Epochs 474/1000 - Loss: 1.0233111381530762 - Metric: 0.5269327759742737\n",
      "----- 0.184s -----\n",
      "Epochs 475/1000 - Loss: 1.023307204246521 - Metric: 0.5267688632011414\n",
      "----- 0.184s -----\n",
      "Epochs 476/1000 - Loss: 1.023303508758545 - Metric: 0.5268794894218445\n",
      "----- 0.185s -----\n",
      "Epochs 477/1000 - Loss: 1.0233006477355957 - Metric: 0.5268166065216064\n",
      "----- 0.193s -----\n",
      "Epochs 478/1000 - Loss: 1.0232981443405151 - Metric: 0.5268360376358032\n",
      "----- 0.176s -----\n",
      "Epochs 479/1000 - Loss: 1.0232961177825928 - Metric: 0.5268615484237671\n",
      "----- 0.168s -----\n",
      "Epochs 480/1000 - Loss: 1.0232940912246704 - Metric: 0.5268028974533081\n",
      "----- 0.175s -----\n",
      "Epochs 481/1000 - Loss: 1.0232923030853271 - Metric: 0.5268946886062622\n",
      "----- 0.194s -----\n",
      "Epochs 482/1000 - Loss: 1.0232901573181152 - Metric: 0.526793360710144\n",
      "----- 0.174s -----\n",
      "Epochs 483/1000 - Loss: 1.0232881307601929 - Metric: 0.5269097685813904\n",
      "----- 0.194s -----\n",
      "Epochs 484/1000 - Loss: 1.0232858657836914 - Metric: 0.526787281036377\n",
      "----- 0.185s -----\n",
      "Epochs 485/1000 - Loss: 1.0232834815979004 - Metric: 0.5269023180007935\n",
      "----- 0.184s -----\n",
      "Epochs 486/1000 - Loss: 1.0232808589935303 - Metric: 0.5268014073371887\n",
      "----- 0.178s -----\n",
      "Epochs 487/1000 - Loss: 1.0232784748077393 - Metric: 0.5268958806991577\n",
      "----- 0.186s -----\n",
      "Epochs 488/1000 - Loss: 1.0232760906219482 - Metric: 0.5268251895904541\n",
      "----- 0.19s -----\n",
      "Epochs 489/1000 - Loss: 1.0232737064361572 - Metric: 0.5268806219100952\n",
      "----- 0.18s -----\n",
      "Epochs 490/1000 - Loss: 1.0232716798782349 - Metric: 0.526843249797821\n",
      "----- 0.177s -----\n",
      "Epochs 491/1000 - Loss: 1.0232692956924438 - Metric: 0.526863157749176\n",
      "----- 0.183s -----\n",
      "Epochs 492/1000 - Loss: 1.0232672691345215 - Metric: 0.5268630981445312\n",
      "----- 0.186s -----\n",
      "Epochs 493/1000 - Loss: 1.0232651233673096 - Metric: 0.5268562436103821\n",
      "----- 0.193s -----\n",
      "Epochs 494/1000 - Loss: 1.0232632160186768 - Metric: 0.526877760887146\n",
      "----- 0.202s -----\n",
      "Epochs 495/1000 - Loss: 1.0232611894607544 - Metric: 0.52684485912323\n",
      "----- 0.192s -----\n",
      "Epochs 496/1000 - Loss: 1.0232592821121216 - Metric: 0.5268906950950623\n",
      "----- 0.193s -----\n",
      "Epochs 497/1000 - Loss: 1.0232574939727783 - Metric: 0.5268453359603882\n",
      "----- 0.188s -----\n",
      "Epochs 498/1000 - Loss: 1.0232555866241455 - Metric: 0.5269039869308472\n",
      "----- 0.188s -----\n",
      "Epochs 499/1000 - Loss: 1.0232536792755127 - Metric: 0.5268380045890808\n",
      "----- 0.19s -----\n",
      "Epochs 500/1000 - Loss: 1.0232517719268799 - Metric: 0.5269066691398621\n",
      "----- 0.189s -----\n",
      "Epochs 501/1000 - Loss: 1.0232499837875366 - Metric: 0.5268380641937256\n",
      "----- 0.186s -----\n",
      "Epochs 502/1000 - Loss: 1.0232481956481934 - Metric: 0.5269197225570679\n",
      "----- 0.197s -----\n",
      "Epochs 503/1000 - Loss: 1.02324640750885 - Metric: 0.5268425345420837\n",
      "----- 0.203s -----\n",
      "Epochs 504/1000 - Loss: 1.0232446193695068 - Metric: 0.5269271731376648\n",
      "----- 0.215s -----\n",
      "Epochs 505/1000 - Loss: 1.0232429504394531 - Metric: 0.5268447995185852\n",
      "----- 0.193s -----\n",
      "Epochs 506/1000 - Loss: 1.0232412815093994 - Metric: 0.5269368290901184\n",
      "----- 0.214s -----\n",
      "Epochs 507/1000 - Loss: 1.0232396125793457 - Metric: 0.5268445014953613\n",
      "----- 0.213s -----\n",
      "Epochs 508/1000 - Loss: 1.023237943649292 - Metric: 0.5269381999969482\n",
      "----- 0.201s -----\n",
      "Epochs 509/1000 - Loss: 1.0232365131378174 - Metric: 0.5268415808677673\n",
      "----- 0.248s -----\n",
      "Epochs 510/1000 - Loss: 1.0232349634170532 - Metric: 0.5269517302513123\n",
      "----- 0.284s -----\n",
      "Epochs 511/1000 - Loss: 1.023233413696289 - Metric: 0.5268509984016418\n",
      "----- 0.209s -----\n",
      "Epochs 512/1000 - Loss: 1.0232319831848145 - Metric: 0.5269611477851868\n",
      "----- 0.209s -----\n",
      "Epochs 513/1000 - Loss: 1.0232305526733398 - Metric: 0.5268473625183105\n",
      "----- 0.231s -----\n",
      "Epochs 514/1000 - Loss: 1.0232291221618652 - Metric: 0.5269657969474792\n",
      "----- 0.205s -----\n",
      "Epochs 515/1000 - Loss: 1.0232278108596802 - Metric: 0.526847243309021\n",
      "----- 0.211s -----\n",
      "Epochs 516/1000 - Loss: 1.0232264995574951 - Metric: 0.5269774198532104\n",
      "----- 0.239s -----\n",
      "Epochs 517/1000 - Loss: 1.0232254266738892 - Metric: 0.526848316192627\n",
      "----- 0.221s -----\n",
      "Epochs 518/1000 - Loss: 1.0232243537902832 - Metric: 0.5269927978515625\n",
      "----- 0.217s -----\n",
      "Epochs 519/1000 - Loss: 1.0232234001159668 - Metric: 0.5268474817276001\n",
      "----- 0.216s -----\n",
      "Epochs 520/1000 - Loss: 1.0232223272323608 - Metric: 0.5270044207572937\n",
      "----- 0.246s -----\n",
      "Epochs 521/1000 - Loss: 1.023221492767334 - Metric: 0.5268429517745972\n",
      "----- 0.228s -----\n",
      "Epochs 522/1000 - Loss: 1.0232207775115967 - Metric: 0.5270294547080994\n",
      "----- 0.227s -----\n",
      "Epochs 523/1000 - Loss: 1.0232203006744385 - Metric: 0.5268483757972717\n",
      "----- 0.236s -----\n",
      "Epochs 524/1000 - Loss: 1.0232197046279907 - Metric: 0.5270474553108215\n",
      "----- 0.232s -----\n",
      "Epochs 525/1000 - Loss: 1.023219108581543 - Metric: 0.5268429517745972\n",
      "----- 0.233s -----\n",
      "Epochs 526/1000 - Loss: 1.0232185125350952 - Metric: 0.5270620584487915\n",
      "----- 0.247s -----\n",
      "Epochs 527/1000 - Loss: 1.0232179164886475 - Metric: 0.5268442034721375\n",
      "----- 0.24s -----\n",
      "Epochs 528/1000 - Loss: 1.0232172012329102 - Metric: 0.5270744562149048\n",
      "----- 0.225s -----\n",
      "Epochs 529/1000 - Loss: 1.0232162475585938 - Metric: 0.5268540978431702\n",
      "----- 0.216s -----\n",
      "Epochs 530/1000 - Loss: 1.0232155323028564 - Metric: 0.5270806550979614\n",
      "----- 0.229s -----\n",
      "Epochs 531/1000 - Loss: 1.0232141017913818 - Metric: 0.5268696546554565\n",
      "----- 0.232s -----\n",
      "Epochs 532/1000 - Loss: 1.0232129096984863 - Metric: 0.5270695090293884\n",
      "----- 0.224s -----\n",
      "Epochs 533/1000 - Loss: 1.0232114791870117 - Metric: 0.5268937349319458\n",
      "----- 0.246s -----\n",
      "Epochs 534/1000 - Loss: 1.0232102870941162 - Metric: 0.527062177658081\n",
      "----- 0.246s -----\n",
      "Epochs 535/1000 - Loss: 1.0232093334197998 - Metric: 0.5269247889518738\n",
      "----- 0.227s -----\n",
      "Epochs 536/1000 - Loss: 1.0232082605361938 - Metric: 0.5270425081253052\n",
      "----- 0.228s -----\n",
      "Epochs 537/1000 - Loss: 1.0232075452804565 - Metric: 0.5269486904144287\n",
      "----- 0.23s -----\n",
      "Epochs 538/1000 - Loss: 1.0232067108154297 - Metric: 0.527031421661377\n",
      "----- 0.229s -----\n",
      "Epochs 539/1000 - Loss: 1.0232062339782715 - Metric: 0.526972234249115\n",
      "----- 0.226s -----\n",
      "Epochs 540/1000 - Loss: 1.0232055187225342 - Metric: 0.527021050453186\n",
      "----- 0.219s -----\n",
      "Epochs 541/1000 - Loss: 1.023205280303955 - Metric: 0.5269873142242432\n",
      "----- 0.231s -----\n",
      "Epochs 542/1000 - Loss: 1.0232048034667969 - Metric: 0.5270175933837891\n",
      "----- 0.246s -----\n",
      "Epochs 543/1000 - Loss: 1.0232044458389282 - Metric: 0.527003824710846\n",
      "----- 0.209s -----\n",
      "Epochs 544/1000 - Loss: 1.0232042074203491 - Metric: 0.527015745639801\n",
      "----- 0.214s -----\n",
      "Epochs 545/1000 - Loss: 1.0232038497924805 - Metric: 0.527007520198822\n",
      "----- 0.205s -----\n",
      "Epochs 546/1000 - Loss: 1.0232034921646118 - Metric: 0.5270154476165771\n",
      "----- 0.229s -----\n",
      "Epochs 547/1000 - Loss: 1.0232033729553223 - Metric: 0.5270222425460815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.247s -----\n",
      "Epochs 548/1000 - Loss: 1.0232031345367432 - Metric: 0.5270208716392517\n",
      "----- 0.214s -----\n",
      "Epochs 549/1000 - Loss: 1.0232030153274536 - Metric: 0.5270304083824158\n",
      "----- 0.215s -----\n",
      "Epochs 550/1000 - Loss: 1.0232027769088745 - Metric: 0.5270249843597412\n",
      "----- 0.217s -----\n",
      "Epochs 551/1000 - Loss: 1.023202657699585 - Metric: 0.5270346403121948\n",
      "----- 0.228s -----\n",
      "Epochs 552/1000 - Loss: 1.0232024192810059 - Metric: 0.5270259976387024\n",
      "----- 0.224s -----\n",
      "Epochs 553/1000 - Loss: 1.0232021808624268 - Metric: 0.527044951915741\n",
      "----- 0.224s -----\n",
      "Epochs 554/1000 - Loss: 1.0232019424438477 - Metric: 0.5270339250564575\n",
      "----- 0.217s -----\n",
      "Epochs 555/1000 - Loss: 1.0232019424438477 - Metric: 0.5270557403564453\n",
      "----- 0.229s -----\n",
      "Epochs 556/1000 - Loss: 1.0232017040252686 - Metric: 0.527031421661377\n",
      "----- 0.223s -----\n",
      "Epochs 557/1000 - Loss: 1.0232017040252686 - Metric: 0.5270635485649109\n",
      "----- 0.216s -----\n",
      "Epochs 558/1000 - Loss: 1.0232014656066895 - Metric: 0.5270309448242188\n",
      "----- 0.225s -----\n",
      "Epochs 559/1000 - Loss: 1.0232014656066895 - Metric: 0.52707839012146\n",
      "----- 0.219s -----\n",
      "Epochs 560/1000 - Loss: 1.0232014656066895 - Metric: 0.5270285606384277\n",
      "----- 0.221s -----\n",
      "Epochs 561/1000 - Loss: 1.0232014656066895 - Metric: 0.5270957946777344\n",
      "----- 0.219s -----\n",
      "Epochs 562/1000 - Loss: 1.023201584815979 - Metric: 0.5270208716392517\n",
      "----- 0.213s -----\n",
      "Epochs 563/1000 - Loss: 1.0232017040252686 - Metric: 0.5271086692810059\n",
      "----- 0.211s -----\n",
      "Epochs 564/1000 - Loss: 1.0232017040252686 - Metric: 0.5270064473152161\n",
      "----- 0.207s -----\n",
      "Epochs 565/1000 - Loss: 1.0232020616531372 - Metric: 0.5271376967430115\n",
      "----- 0.216s -----\n",
      "Epochs 566/1000 - Loss: 1.0232023000717163 - Metric: 0.5270057320594788\n",
      "----- 0.21s -----\n",
      "Epochs 567/1000 - Loss: 1.023202896118164 - Metric: 0.5271785259246826\n",
      "----- 0.233s -----\n",
      "Epochs 568/1000 - Loss: 1.02320396900177 - Metric: 0.5269942283630371\n",
      "----- 0.236s -----\n",
      "Epochs 569/1000 - Loss: 1.023205041885376 - Metric: 0.5272120237350464\n",
      "----- 0.192s -----\n",
      "Epochs 570/1000 - Loss: 1.0232062339782715 - Metric: 0.5269650220870972\n",
      "----- 0.212s -----\n",
      "Epochs 571/1000 - Loss: 1.0232077836990356 - Metric: 0.5272353887557983\n",
      "----- 0.238s -----\n",
      "Epochs 572/1000 - Loss: 1.0232090950012207 - Metric: 0.5269368886947632\n",
      "----- 0.234s -----\n",
      "Epochs 573/1000 - Loss: 1.0232105255126953 - Metric: 0.5272655487060547\n",
      "----- 0.203s -----\n",
      "Epochs 574/1000 - Loss: 1.0232113599777222 - Metric: 0.5269247889518738\n",
      "----- 0.215s -----\n",
      "Epochs 575/1000 - Loss: 1.0232112407684326 - Metric: 0.5272730588912964\n",
      "----- 0.203s -----\n",
      "Epochs 576/1000 - Loss: 1.0232104063034058 - Metric: 0.526927649974823\n",
      "----- 0.207s -----\n",
      "Epochs 577/1000 - Loss: 1.023208737373352 - Metric: 0.5272558331489563\n",
      "----- 0.191s -----\n",
      "Epochs 578/1000 - Loss: 1.0232062339782715 - Metric: 0.5269631743431091\n",
      "----- 0.199s -----\n",
      "Epochs 579/1000 - Loss: 1.023203730583191 - Metric: 0.5269858241081238\n",
      "----- 0.208s -----\n",
      "Epochs 580/1000 - Loss: 1.0231997966766357 - Metric: 0.5270465016365051\n",
      "----- 0.21s -----\n",
      "Epochs 581/1000 - Loss: 1.0231990814208984 - Metric: 0.5271216034889221\n",
      "----- 0.231s -----\n",
      "Epochs 582/1000 - Loss: 1.023201584815979 - Metric: 0.52718186378479\n",
      "----- 0.203s -----\n",
      "Epochs 583/1000 - Loss: 1.0232030153274536 - Metric: 0.5272034406661987\n",
      "----- 0.204s -----\n",
      "Epochs 584/1000 - Loss: 1.0232014656066895 - Metric: 0.5271807909011841\n",
      "----- 0.2s -----\n",
      "Epochs 585/1000 - Loss: 1.023199200630188 - Metric: 0.5271283388137817\n",
      "----- 0.199s -----\n",
      "Epochs 586/1000 - Loss: 1.0231989622116089 - Metric: 0.5270705819129944\n",
      "----- 0.2s -----\n",
      "Epochs 587/1000 - Loss: 1.023200511932373 - Metric: 0.5270295739173889\n",
      "----- 0.201s -----\n",
      "Epochs 588/1000 - Loss: 1.0232012271881104 - Metric: 0.5270172953605652\n",
      "----- 0.201s -----\n",
      "Epochs 589/1000 - Loss: 1.0232000350952148 - Metric: 0.5270346403121948\n",
      "----- 0.205s -----\n",
      "Epochs 590/1000 - Loss: 1.0231988430023193 - Metric: 0.5270731449127197\n",
      "----- 0.187s -----\n",
      "Epochs 591/1000 - Loss: 1.0231988430023193 - Metric: 0.5271169543266296\n",
      "----- 0.188s -----\n",
      "Epochs 592/1000 - Loss: 1.0231997966766357 - Metric: 0.5271483659744263\n",
      "----- 0.208s -----\n",
      "Epochs 593/1000 - Loss: 1.0232001543045044 - Metric: 0.5271556377410889\n",
      "----- 0.188s -----\n",
      "Epochs 594/1000 - Loss: 1.0231993198394775 - Metric: 0.5271379351615906\n",
      "----- 0.201s -----\n",
      "Epochs 595/1000 - Loss: 1.0231986045837402 - Metric: 0.5271049737930298\n",
      "----- 0.187s -----\n",
      "Epochs 596/1000 - Loss: 1.0231988430023193 - Metric: 0.5270711183547974\n",
      "----- 0.194s -----\n",
      "Epochs 597/1000 - Loss: 1.0231993198394775 - Metric: 0.5270490050315857\n",
      "----- 0.198s -----\n",
      "Epochs 598/1000 - Loss: 1.0231995582580566 - Metric: 0.5270453095436096\n",
      "----- 0.213s -----\n",
      "Epochs 599/1000 - Loss: 1.0231989622116089 - Metric: 0.5270593762397766\n",
      "----- 0.196s -----\n",
      "Epochs 600/1000 - Loss: 1.0231986045837402 - Metric: 0.5270848274230957\n",
      "----- 0.19s -----\n",
      "Epochs 601/1000 - Loss: 1.0231986045837402 - Metric: 0.5271113514900208\n",
      "----- 0.194s -----\n",
      "Epochs 602/1000 - Loss: 1.0231988430023193 - Metric: 0.5271288156509399\n",
      "----- 0.191s -----\n",
      "Epochs 603/1000 - Loss: 1.0231989622116089 - Metric: 0.5271311402320862\n",
      "----- 0.193s -----\n",
      "Epochs 604/1000 - Loss: 1.0231987237930298 - Metric: 0.5271190404891968\n",
      "----- 0.189s -----\n",
      "Epochs 605/1000 - Loss: 1.0231984853744507 - Metric: 0.5270987749099731\n",
      "----- 0.189s -----\n",
      "Epochs 606/1000 - Loss: 1.0231986045837402 - Metric: 0.5270795226097107\n",
      "----- 0.19s -----\n",
      "Epochs 607/1000 - Loss: 1.0231988430023193 - Metric: 0.5270686745643616\n",
      "----- 0.19s -----\n",
      "Epochs 608/1000 - Loss: 1.0231988430023193 - Metric: 0.5270693302154541\n",
      "----- 0.189s -----\n",
      "Epochs 609/1000 - Loss: 1.0231986045837402 - Metric: 0.5270802974700928\n",
      "----- 0.195s -----\n",
      "Epochs 610/1000 - Loss: 1.0231984853744507 - Metric: 0.5270967483520508\n",
      "----- 0.182s -----\n",
      "Epochs 611/1000 - Loss: 1.0231984853744507 - Metric: 0.5271116495132446\n",
      "----- 0.189s -----\n",
      "Epochs 612/1000 - Loss: 1.0231986045837402 - Metric: 0.5271193981170654\n",
      "----- 0.199s -----\n",
      "Epochs 613/1000 - Loss: 1.0231986045837402 - Metric: 0.5271177291870117\n",
      "----- 0.192s -----\n",
      "Epochs 614/1000 - Loss: 1.0231984853744507 - Metric: 0.5271080732345581\n",
      "----- 0.192s -----\n",
      "Epochs 615/1000 - Loss: 1.0231984853744507 - Metric: 0.5270954370498657\n",
      "----- 0.188s -----\n",
      "Epochs 616/1000 - Loss: 1.0231984853744507 - Metric: 0.5270850658416748\n",
      "----- 0.187s -----\n",
      "Epochs 617/1000 - Loss: 1.0231984853744507 - Metric: 0.5270808339118958\n",
      "----- 0.188s -----\n",
      "Epochs 618/1000 - Loss: 1.0231984853744507 - Metric: 0.5270838141441345\n",
      "----- 0.191s -----\n",
      "Epochs 619/1000 - Loss: 1.0231984853744507 - Metric: 0.5270922780036926\n",
      "----- 0.193s -----\n",
      "Epochs 620/1000 - Loss: 1.0231983661651611 - Metric: 0.5271022319793701\n",
      "----- 0.197s -----\n",
      "Epochs 621/1000 - Loss: 1.0231983661651611 - Metric: 0.5271094441413879\n",
      "----- 0.186s -----\n",
      "Epochs 622/1000 - Loss: 1.0231984853744507 - Metric: 0.5271115899085999\n",
      "----- 0.181s -----\n",
      "Epochs 623/1000 - Loss: 1.0231983661651611 - Metric: 0.527108371257782\n",
      "----- 0.183s -----\n",
      "Epochs 624/1000 - Loss: 1.0231983661651611 - Metric: 0.5271021723747253\n",
      "----- 0.184s -----\n",
      "Epochs 625/1000 - Loss: 1.0231983661651611 - Metric: 0.5270957946777344\n",
      "----- 0.18s -----\n",
      "Epochs 626/1000 - Loss: 1.0231983661651611 - Metric: 0.5270918607711792\n",
      "----- 0.18s -----\n",
      "Epochs 627/1000 - Loss: 1.0231983661651611 - Metric: 0.5270918607711792\n",
      "----- 0.2s -----\n",
      "Epochs 628/1000 - Loss: 1.0231982469558716 - Metric: 0.5270951986312866\n",
      "----- 0.194s -----\n",
      "Epochs 629/1000 - Loss: 1.0231983661651611 - Metric: 0.5271003246307373\n",
      "----- 0.2s -----\n",
      "Epochs 630/1000 - Loss: 1.0231983661651611 - Metric: 0.5271046161651611\n",
      "----- 0.191s -----\n",
      "Epochs 631/1000 - Loss: 1.0231983661651611 - Metric: 0.527106523513794\n",
      "----- 0.19s -----\n",
      "Epochs 632/1000 - Loss: 1.0231983661651611 - Metric: 0.5271060466766357\n",
      "----- 0.188s -----\n",
      "Epochs 633/1000 - Loss: 1.0231982469558716 - Metric: 0.5271037817001343\n",
      "----- 0.193s -----\n",
      "Epochs 634/1000 - Loss: 1.0231982469558716 - Metric: 0.5271011590957642\n",
      "----- 0.197s -----\n",
      "Epochs 635/1000 - Loss: 1.0231982469558716 - Metric: 0.5270993113517761\n",
      "----- 0.199s -----\n",
      "Epochs 636/1000 - Loss: 1.0231982469558716 - Metric: 0.5270990133285522\n",
      "----- 0.195s -----\n",
      "Epochs 637/1000 - Loss: 1.0231982469558716 - Metric: 0.5270998477935791\n",
      "----- 0.198s -----\n",
      "Epochs 638/1000 - Loss: 1.023198127746582 - Metric: 0.5271013379096985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.196s -----\n",
      "Epochs 639/1000 - Loss: 1.0231982469558716 - Metric: 0.527103066444397\n",
      "----- 0.193s -----\n",
      "Epochs 640/1000 - Loss: 1.0231983661651611 - Metric: 0.5271043181419373\n",
      "----- 0.204s -----\n",
      "Epochs 641/1000 - Loss: 1.0231982469558716 - Metric: 0.5271046757698059\n",
      "----- 0.192s -----\n",
      "Epochs 642/1000 - Loss: 1.0231982469558716 - Metric: 0.5271047949790955\n",
      "----- 0.19s -----\n",
      "Epochs 643/1000 - Loss: 1.0231982469558716 - Metric: 0.5271045565605164\n",
      "----- 0.198s -----\n",
      "Epochs 644/1000 - Loss: 1.0231982469558716 - Metric: 0.5271043181419373\n",
      "----- 0.204s -----\n",
      "Epochs 645/1000 - Loss: 1.0231982469558716 - Metric: 0.5271039009094238\n",
      "----- 0.205s -----\n",
      "Epochs 646/1000 - Loss: 1.023198127746582 - Metric: 0.5271036028862\n",
      "----- 0.208s -----\n",
      "Epochs 647/1000 - Loss: 1.0231982469558716 - Metric: 0.5271035432815552\n",
      "----- 0.203s -----\n",
      "Epochs 648/1000 - Loss: 1.0231982469558716 - Metric: 0.5271039009094238\n",
      "----- 0.219s -----\n",
      "Epochs 649/1000 - Loss: 1.0231982469558716 - Metric: 0.5271046161651611\n",
      "----- 0.21s -----\n",
      "Epochs 650/1000 - Loss: 1.0231982469558716 - Metric: 0.5271053910255432\n",
      "----- 0.216s -----\n",
      "Epochs 651/1000 - Loss: 1.023198127746582 - Metric: 0.5271061658859253\n",
      "----- 0.197s -----\n",
      "Epochs 652/1000 - Loss: 1.023198127746582 - Metric: 0.527106761932373\n",
      "----- 0.21s -----\n",
      "Epochs 653/1000 - Loss: 1.023198127746582 - Metric: 0.5271069407463074\n",
      "----- 0.23s -----\n",
      "Epochs 654/1000 - Loss: 1.023198127746582 - Metric: 0.527106761932373\n",
      "----- 0.208s -----\n",
      "Epochs 655/1000 - Loss: 1.0231982469558716 - Metric: 0.527106523513794\n",
      "----- 0.2s -----\n",
      "Epochs 656/1000 - Loss: 1.023198127746582 - Metric: 0.5271060466766357\n",
      "----- 0.231s -----\n",
      "Epochs 657/1000 - Loss: 1.023198127746582 - Metric: 0.5271060466766357\n",
      "----- 0.229s -----\n",
      "Epochs 658/1000 - Loss: 1.023198127746582 - Metric: 0.5271064639091492\n",
      "----- 0.208s -----\n",
      "Epochs 659/1000 - Loss: 1.023198127746582 - Metric: 0.5271072387695312\n",
      "----- 0.21s -----\n",
      "Epochs 660/1000 - Loss: 1.023198127746582 - Metric: 0.5271080136299133\n",
      "----- 0.204s -----\n",
      "Epochs 661/1000 - Loss: 1.023198127746582 - Metric: 0.5271084308624268\n",
      "----- 0.251s -----\n",
      "Epochs 662/1000 - Loss: 1.023198127746582 - Metric: 0.5271086692810059\n",
      "----- 0.208s -----\n",
      "Epochs 663/1000 - Loss: 1.0231982469558716 - Metric: 0.5271086692810059\n",
      "----- 0.227s -----\n",
      "Epochs 664/1000 - Loss: 1.023198127746582 - Metric: 0.5271088480949402\n",
      "----- 0.234s -----\n",
      "Epochs 665/1000 - Loss: 1.023198127746582 - Metric: 0.5271089673042297\n",
      "----- 0.225s -----\n",
      "Epochs 666/1000 - Loss: 1.023198127746582 - Metric: 0.5271089673042297\n",
      "----- 0.202s -----\n",
      "Epochs 667/1000 - Loss: 1.023198127746582 - Metric: 0.5271092057228088\n",
      "----- 0.212s -----\n",
      "Epochs 668/1000 - Loss: 1.023198127746582 - Metric: 0.5271093845367432\n",
      "----- 0.208s -----\n",
      "Epochs 669/1000 - Loss: 1.0231980085372925 - Metric: 0.5271099209785461\n",
      "----- 0.233s -----\n",
      "Epochs 670/1000 - Loss: 1.023198127746582 - Metric: 0.5271103382110596\n",
      "----- 0.229s -----\n",
      "Epochs 671/1000 - Loss: 1.023198127746582 - Metric: 0.527110755443573\n",
      "----- 0.218s -----\n",
      "Epochs 672/1000 - Loss: 1.023198127746582 - Metric: 0.5271111130714417\n",
      "----- 0.267s -----\n",
      "Epochs 673/1000 - Loss: 1.023198127746582 - Metric: 0.5271112322807312\n",
      "----- 0.239s -----\n",
      "Epochs 674/1000 - Loss: 1.023198127746582 - Metric: 0.5271111726760864\n",
      "----- 0.236s -----\n",
      "Epochs 675/1000 - Loss: 1.023198127746582 - Metric: 0.5271109938621521\n",
      "----- 0.223s -----\n",
      "Epochs 676/1000 - Loss: 1.023198127746582 - Metric: 0.5271111726760864\n",
      "----- 0.222s -----\n",
      "Epochs 677/1000 - Loss: 1.023198127746582 - Metric: 0.5271115303039551\n",
      "----- 0.238s -----\n",
      "Epochs 678/1000 - Loss: 1.023198127746582 - Metric: 0.527111828327179\n",
      "----- 0.216s -----\n",
      "Epochs 679/1000 - Loss: 1.023198127746582 - Metric: 0.5271121859550476\n",
      "----- 0.254s -----\n",
      "Epochs 680/1000 - Loss: 1.023198127746582 - Metric: 0.5271127223968506\n",
      "----- 0.216s -----\n",
      "Epochs 681/1000 - Loss: 1.023198127746582 - Metric: 0.5271132588386536\n",
      "----- 0.227s -----\n",
      "Epochs 682/1000 - Loss: 1.0231980085372925 - Metric: 0.5271134972572327\n",
      "----- 0.236s -----\n",
      "Epochs 683/1000 - Loss: 1.0231980085372925 - Metric: 0.5271132588386536\n",
      "----- 0.219s -----\n",
      "Epochs 684/1000 - Loss: 1.0231980085372925 - Metric: 0.5271129608154297\n",
      "----- 0.223s -----\n",
      "Epochs 685/1000 - Loss: 1.023198127746582 - Metric: 0.5271131992340088\n",
      "----- 0.245s -----\n",
      "Epochs 686/1000 - Loss: 1.023197889328003 - Metric: 0.5271132588386536\n",
      "----- 0.236s -----\n",
      "Epochs 687/1000 - Loss: 1.0231980085372925 - Metric: 0.527113676071167\n",
      "----- 0.232s -----\n",
      "Epochs 688/1000 - Loss: 1.023198127746582 - Metric: 0.5271142721176147\n",
      "----- 0.271s -----\n",
      "Epochs 689/1000 - Loss: 1.0231980085372925 - Metric: 0.5271144509315491\n",
      "----- 0.245s -----\n",
      "Epochs 690/1000 - Loss: 1.0231980085372925 - Metric: 0.5271144509315491\n",
      "----- 0.202s -----\n",
      "Epochs 691/1000 - Loss: 1.023197889328003 - Metric: 0.5271146297454834\n",
      "----- 0.206s -----\n",
      "Epochs 692/1000 - Loss: 1.023197889328003 - Metric: 0.5271149277687073\n",
      "----- 0.222s -----\n",
      "Epochs 693/1000 - Loss: 1.0231980085372925 - Metric: 0.5271152853965759\n",
      "----- 0.21s -----\n",
      "Epochs 694/1000 - Loss: 1.023198127746582 - Metric: 0.5271153450012207\n",
      "----- 0.211s -----\n",
      "Epochs 695/1000 - Loss: 1.0231980085372925 - Metric: 0.5271153450012207\n",
      "----- 0.216s -----\n",
      "Epochs 696/1000 - Loss: 1.0231980085372925 - Metric: 0.5271156430244446\n",
      "----- 0.237s -----\n",
      "Epochs 697/1000 - Loss: 1.023197889328003 - Metric: 0.527116060256958\n",
      "----- 0.214s -----\n",
      "Epochs 698/1000 - Loss: 1.0231980085372925 - Metric: 0.5271164774894714\n",
      "----- 0.206s -----\n",
      "Epochs 699/1000 - Loss: 1.023197889328003 - Metric: 0.5271166563034058\n",
      "----- 0.205s -----\n",
      "Epochs 700/1000 - Loss: 1.023197889328003 - Metric: 0.5271165370941162\n",
      "----- 0.215s -----\n",
      "Epochs 701/1000 - Loss: 1.023198127746582 - Metric: 0.5271164178848267\n",
      "----- 0.248s -----\n",
      "Epochs 702/1000 - Loss: 1.023197889328003 - Metric: 0.5271164774894714\n",
      "----- 0.242s -----\n",
      "Epochs 703/1000 - Loss: 1.023197889328003 - Metric: 0.5271170139312744\n",
      "----- 0.207s -----\n",
      "Epochs 704/1000 - Loss: 1.0231980085372925 - Metric: 0.5271173715591431\n",
      "----- 0.206s -----\n",
      "Epochs 705/1000 - Loss: 1.023197889328003 - Metric: 0.5271176695823669\n",
      "----- 0.23s -----\n",
      "Epochs 706/1000 - Loss: 1.023197889328003 - Metric: 0.5271178483963013\n",
      "----- 0.205s -----\n",
      "Epochs 707/1000 - Loss: 1.023197889328003 - Metric: 0.5271178483963013\n",
      "----- 0.213s -----\n",
      "Epochs 708/1000 - Loss: 1.023197889328003 - Metric: 0.5271177887916565\n",
      "----- 0.225s -----\n",
      "Epochs 709/1000 - Loss: 1.023197889328003 - Metric: 0.527117908000946\n",
      "----- 0.204s -----\n",
      "Epochs 710/1000 - Loss: 1.023197889328003 - Metric: 0.5271182656288147\n",
      "----- 0.202s -----\n",
      "Epochs 711/1000 - Loss: 1.0231977701187134 - Metric: 0.5271186232566833\n",
      "----- 0.206s -----\n",
      "Epochs 712/1000 - Loss: 1.023197889328003 - Metric: 0.5271191000938416\n",
      "----- 0.2s -----\n",
      "Epochs 713/1000 - Loss: 1.023197889328003 - Metric: 0.5271194577217102\n",
      "----- 0.216s -----\n",
      "Epochs 714/1000 - Loss: 1.023197889328003 - Metric: 0.5271197557449341\n",
      "----- 0.197s -----\n",
      "Epochs 715/1000 - Loss: 1.023197889328003 - Metric: 0.5271196365356445\n",
      "----- 0.191s -----\n",
      "Epochs 716/1000 - Loss: 1.023197889328003 - Metric: 0.5271195769309998\n",
      "----- 0.198s -----\n",
      "Epochs 717/1000 - Loss: 1.0231980085372925 - Metric: 0.5271197557449341\n",
      "----- 0.193s -----\n",
      "Epochs 718/1000 - Loss: 1.023197889328003 - Metric: 0.5271199941635132\n",
      "----- 0.191s -----\n",
      "Epochs 719/1000 - Loss: 1.023197889328003 - Metric: 0.5271201133728027\n",
      "----- 0.189s -----\n",
      "Epochs 720/1000 - Loss: 1.023197889328003 - Metric: 0.5271204113960266\n",
      "----- 0.214s -----\n",
      "Epochs 721/1000 - Loss: 1.023197889328003 - Metric: 0.5271207094192505\n",
      "----- 0.208s -----\n",
      "Epochs 722/1000 - Loss: 1.023197889328003 - Metric: 0.5271210074424744\n",
      "----- 0.195s -----\n",
      "Epochs 723/1000 - Loss: 1.023197889328003 - Metric: 0.5271214246749878\n",
      "----- 0.189s -----\n",
      "Epochs 724/1000 - Loss: 1.023197889328003 - Metric: 0.5271217823028564\n",
      "----- 0.19s -----\n",
      "Epochs 725/1000 - Loss: 1.023197889328003 - Metric: 0.5271214842796326\n",
      "----- 0.196s -----\n",
      "Epochs 726/1000 - Loss: 1.023197889328003 - Metric: 0.5271216034889221\n",
      "----- 0.19s -----\n",
      "Epochs 727/1000 - Loss: 1.023197889328003 - Metric: 0.5271219611167908\n",
      "----- 0.193s -----\n",
      "Epochs 728/1000 - Loss: 1.023197889328003 - Metric: 0.5271225571632385\n",
      "----- 0.205s -----\n",
      "Epochs 729/1000 - Loss: 1.0231977701187134 - Metric: 0.5271226763725281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.193s -----\n",
      "Epochs 730/1000 - Loss: 1.023197889328003 - Metric: 0.5271226763725281\n",
      "----- 0.202s -----\n",
      "Epochs 731/1000 - Loss: 1.0231977701187134 - Metric: 0.5271227955818176\n",
      "----- 0.193s -----\n",
      "Epochs 732/1000 - Loss: 1.0231977701187134 - Metric: 0.5271230340003967\n",
      "----- 0.192s -----\n",
      "Epochs 733/1000 - Loss: 1.023197889328003 - Metric: 0.5271230340003967\n",
      "----- 0.217s -----\n",
      "Epochs 734/1000 - Loss: 1.0231977701187134 - Metric: 0.527123212814331\n",
      "----- 0.188s -----\n",
      "Epochs 735/1000 - Loss: 1.023197889328003 - Metric: 0.527123749256134\n",
      "----- 0.191s -----\n",
      "Epochs 736/1000 - Loss: 1.023197889328003 - Metric: 0.5271238088607788\n",
      "----- 0.196s -----\n",
      "Epochs 737/1000 - Loss: 1.0231977701187134 - Metric: 0.527123749256134\n",
      "----- 0.187s -----\n",
      "Epochs 738/1000 - Loss: 1.0231977701187134 - Metric: 0.5271238088607788\n",
      "----- 0.19s -----\n",
      "Epochs 739/1000 - Loss: 1.0231977701187134 - Metric: 0.5271243453025818\n",
      "----- 0.187s -----\n",
      "Epochs 740/1000 - Loss: 1.0231977701187134 - Metric: 0.52712482213974\n",
      "----- 0.195s -----\n",
      "Epochs 741/1000 - Loss: 1.0231977701187134 - Metric: 0.5271252393722534\n",
      "----- 0.192s -----\n",
      "Epochs 742/1000 - Loss: 1.0231976509094238 - Metric: 0.5271252989768982\n",
      "----- 0.197s -----\n",
      "Epochs 743/1000 - Loss: 1.0231977701187134 - Metric: 0.5271250009536743\n",
      "----- 0.229s -----\n",
      "Epochs 744/1000 - Loss: 1.0231977701187134 - Metric: 0.5271247029304504\n",
      "----- 0.201s -----\n",
      "Epochs 745/1000 - Loss: 1.023197889328003 - Metric: 0.5271251201629639\n",
      "----- 0.179s -----\n",
      "Epochs 746/1000 - Loss: 1.0231977701187134 - Metric: 0.5271255373954773\n",
      "----- 0.182s -----\n",
      "Epochs 747/1000 - Loss: 1.0231976509094238 - Metric: 0.527125895023346\n",
      "----- 0.189s -----\n",
      "Epochs 748/1000 - Loss: 1.0231977701187134 - Metric: 0.5271262526512146\n",
      "----- 0.193s -----\n",
      "Epochs 749/1000 - Loss: 1.0231977701187134 - Metric: 0.5271264314651489\n",
      "----- 0.181s -----\n",
      "Epochs 750/1000 - Loss: 1.0231977701187134 - Metric: 0.5271264314651489\n",
      "----- 0.186s -----\n",
      "Epochs 751/1000 - Loss: 1.0231977701187134 - Metric: 0.5271264910697937\n",
      "----- 0.184s -----\n",
      "Epochs 752/1000 - Loss: 1.0231977701187134 - Metric: 0.5271264910697937\n",
      "----- 0.207s -----\n",
      "Epochs 753/1000 - Loss: 1.023197889328003 - Metric: 0.5271264910697937\n",
      "----- 0.184s -----\n",
      "Epochs 754/1000 - Loss: 1.0231977701187134 - Metric: 0.5271269679069519\n",
      "----- 0.185s -----\n",
      "Epochs 755/1000 - Loss: 1.0231977701187134 - Metric: 0.5271276235580444\n",
      "----- 0.224s -----\n",
      "Epochs 756/1000 - Loss: 1.0231977701187134 - Metric: 0.5271281003952026\n",
      "----- 0.177s -----\n",
      "Epochs 757/1000 - Loss: 1.0231977701187134 - Metric: 0.5271280407905579\n",
      "----- 0.177s -----\n",
      "Epochs 758/1000 - Loss: 1.0231977701187134 - Metric: 0.5271280407905579\n",
      "----- 0.18s -----\n",
      "Epochs 759/1000 - Loss: 1.0231976509094238 - Metric: 0.5271281599998474\n",
      "----- 0.177s -----\n",
      "Epochs 760/1000 - Loss: 1.0231977701187134 - Metric: 0.5271283388137817\n",
      "----- 0.18s -----\n",
      "Epochs 761/1000 - Loss: 1.0231977701187134 - Metric: 0.5271282196044922\n",
      "----- 0.188s -----\n",
      "Epochs 762/1000 - Loss: 1.0231977701187134 - Metric: 0.5271282196044922\n",
      "----- 0.184s -----\n",
      "Epochs 763/1000 - Loss: 1.0231976509094238 - Metric: 0.5271281599998474\n",
      "----- 0.194s -----\n",
      "Epochs 764/1000 - Loss: 1.0231977701187134 - Metric: 0.5271285176277161\n",
      "----- 0.173s -----\n",
      "Epochs 765/1000 - Loss: 1.0231977701187134 - Metric: 0.5271286964416504\n",
      "----- 0.175s -----\n",
      "Epochs 766/1000 - Loss: 1.0231977701187134 - Metric: 0.5271291136741638\n",
      "----- 0.205s -----\n",
      "Epochs 767/1000 - Loss: 1.0231977701187134 - Metric: 0.5271292924880981\n",
      "----- 0.205s -----\n",
      "Epochs 768/1000 - Loss: 1.0231977701187134 - Metric: 0.5271297097206116\n",
      "----- 0.188s -----\n",
      "Epochs 769/1000 - Loss: 1.0231976509094238 - Metric: 0.5271297693252563\n",
      "----- 0.179s -----\n",
      "Epochs 770/1000 - Loss: 1.0231976509094238 - Metric: 0.5271297097206116\n",
      "----- 0.181s -----\n",
      "Epochs 771/1000 - Loss: 1.0231976509094238 - Metric: 0.5271295309066772\n",
      "----- 0.178s -----\n",
      "Epochs 772/1000 - Loss: 1.0231976509094238 - Metric: 0.5271297097206116\n",
      "----- 0.187s -----\n",
      "Epochs 773/1000 - Loss: 1.0231976509094238 - Metric: 0.5271300673484802\n",
      "----- 0.192s -----\n",
      "Epochs 774/1000 - Loss: 1.0231976509094238 - Metric: 0.5271307826042175\n",
      "----- 0.182s -----\n",
      "Epochs 775/1000 - Loss: 1.0231976509094238 - Metric: 0.5271310806274414\n",
      "----- 0.199s -----\n",
      "Epochs 776/1000 - Loss: 1.0231976509094238 - Metric: 0.5271311402320862\n",
      "----- 0.2s -----\n",
      "Epochs 777/1000 - Loss: 1.0231976509094238 - Metric: 0.5271310806274414\n",
      "----- 0.199s -----\n",
      "Epochs 778/1000 - Loss: 1.0231976509094238 - Metric: 0.5271310210227966\n",
      "----- 0.211s -----\n",
      "Epochs 779/1000 - Loss: 1.0231976509094238 - Metric: 0.5271310806274414\n",
      "----- 0.189s -----\n",
      "Epochs 780/1000 - Loss: 1.0231976509094238 - Metric: 0.5271316170692444\n",
      "----- 0.197s -----\n",
      "Epochs 781/1000 - Loss: 1.0231976509094238 - Metric: 0.5271319150924683\n",
      "----- 0.196s -----\n",
      "Epochs 782/1000 - Loss: 1.0231976509094238 - Metric: 0.5271320939064026\n",
      "----- 0.191s -----\n",
      "Epochs 783/1000 - Loss: 1.0231976509094238 - Metric: 0.5271323323249817\n",
      "----- 0.196s -----\n",
      "Epochs 784/1000 - Loss: 1.0231976509094238 - Metric: 0.5271323323249817\n",
      "----- 0.182s -----\n",
      "Epochs 785/1000 - Loss: 1.0231976509094238 - Metric: 0.527132511138916\n",
      "----- 0.202s -----\n",
      "Epochs 786/1000 - Loss: 1.0231976509094238 - Metric: 0.5271328091621399\n",
      "----- 0.18s -----\n",
      "Epochs 787/1000 - Loss: 1.0231976509094238 - Metric: 0.527133047580719\n",
      "----- 0.202s -----\n",
      "Epochs 788/1000 - Loss: 1.0231976509094238 - Metric: 0.5271335244178772\n",
      "----- 0.188s -----\n",
      "Epochs 789/1000 - Loss: 1.0231976509094238 - Metric: 0.5271335244178772\n",
      "----- 0.191s -----\n",
      "Epochs 790/1000 - Loss: 1.0231975317001343 - Metric: 0.5271332859992981\n",
      "----- 0.201s -----\n",
      "Epochs 791/1000 - Loss: 1.0231976509094238 - Metric: 0.5271334648132324\n",
      "----- 0.184s -----\n",
      "Epochs 792/1000 - Loss: 1.0231976509094238 - Metric: 0.5271337628364563\n",
      "----- 0.215s -----\n",
      "Epochs 793/1000 - Loss: 1.0231976509094238 - Metric: 0.5271340608596802\n",
      "----- 0.186s -----\n",
      "Epochs 794/1000 - Loss: 1.0231976509094238 - Metric: 0.5271344780921936\n",
      "----- 0.218s -----\n",
      "Epochs 795/1000 - Loss: 1.0231975317001343 - Metric: 0.527134895324707\n",
      "----- 0.179s -----\n",
      "Epochs 796/1000 - Loss: 1.0231975317001343 - Metric: 0.5271351337432861\n",
      "----- 0.221s -----\n",
      "Epochs 797/1000 - Loss: 1.0231975317001343 - Metric: 0.5271351933479309\n",
      "----- 0.197s -----\n",
      "Epochs 798/1000 - Loss: 1.0231976509094238 - Metric: 0.5271350741386414\n",
      "----- 0.214s -----\n",
      "Epochs 799/1000 - Loss: 1.0231975317001343 - Metric: 0.5271348357200623\n",
      "----- 0.194s -----\n",
      "Epochs 800/1000 - Loss: 1.0231976509094238 - Metric: 0.5271347761154175\n",
      "----- 0.19s -----\n",
      "Epochs 801/1000 - Loss: 1.0231976509094238 - Metric: 0.5271351337432861\n",
      "----- 0.196s -----\n",
      "Epochs 802/1000 - Loss: 1.0231975317001343 - Metric: 0.5271359086036682\n",
      "----- 0.194s -----\n",
      "Epochs 803/1000 - Loss: 1.0231976509094238 - Metric: 0.5271367430686951\n",
      "----- 0.194s -----\n",
      "Epochs 804/1000 - Loss: 1.0231975317001343 - Metric: 0.5271369218826294\n",
      "----- 0.192s -----\n",
      "Epochs 805/1000 - Loss: 1.0231975317001343 - Metric: 0.5271367430686951\n",
      "----- 0.195s -----\n",
      "Epochs 806/1000 - Loss: 1.0231976509094238 - Metric: 0.5271364450454712\n",
      "----- 0.215s -----\n",
      "Epochs 807/1000 - Loss: 1.0231976509094238 - Metric: 0.5271362662315369\n",
      "----- 0.199s -----\n",
      "Epochs 808/1000 - Loss: 1.0231975317001343 - Metric: 0.5271363258361816\n",
      "----- 0.23s -----\n",
      "Epochs 809/1000 - Loss: 1.0231974124908447 - Metric: 0.5271367430686951\n",
      "----- 0.202s -----\n",
      "Epochs 810/1000 - Loss: 1.0231976509094238 - Metric: 0.5271372199058533\n",
      "----- 0.211s -----\n",
      "Epochs 811/1000 - Loss: 1.0231976509094238 - Metric: 0.5271374583244324\n",
      "----- 0.197s -----\n",
      "Epochs 812/1000 - Loss: 1.0231976509094238 - Metric: 0.5271377563476562\n",
      "----- 0.204s -----\n",
      "Epochs 813/1000 - Loss: 1.0231975317001343 - Metric: 0.527137815952301\n",
      "----- 0.222s -----\n",
      "Epochs 814/1000 - Loss: 1.0231975317001343 - Metric: 0.5271375179290771\n",
      "----- 0.207s -----\n",
      "Epochs 815/1000 - Loss: 1.0231976509094238 - Metric: 0.5271377563476562\n",
      "----- 0.196s -----\n",
      "Epochs 816/1000 - Loss: 1.0231975317001343 - Metric: 0.5271380543708801\n",
      "----- 0.201s -----\n",
      "Epochs 817/1000 - Loss: 1.0231975317001343 - Metric: 0.527138352394104\n",
      "----- 0.223s -----\n",
      "Epochs 818/1000 - Loss: 1.0231974124908447 - Metric: 0.5271386504173279\n",
      "----- 0.21s -----\n",
      "Epochs 819/1000 - Loss: 1.0231975317001343 - Metric: 0.5271386504173279\n",
      "----- 0.211s -----\n",
      "Epochs 820/1000 - Loss: 1.0231976509094238 - Metric: 0.5271387696266174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.209s -----\n",
      "Epochs 821/1000 - Loss: 1.0231975317001343 - Metric: 0.5271388292312622\n",
      "----- 0.198s -----\n",
      "Epochs 822/1000 - Loss: 1.0231975317001343 - Metric: 0.5271389484405518\n",
      "----- 0.211s -----\n",
      "Epochs 823/1000 - Loss: 1.0231975317001343 - Metric: 0.5271395444869995\n",
      "----- 0.22s -----\n",
      "Epochs 824/1000 - Loss: 1.0231975317001343 - Metric: 0.5271399617195129\n",
      "----- 0.208s -----\n",
      "Epochs 825/1000 - Loss: 1.0231974124908447 - Metric: 0.5271400213241577\n",
      "----- 0.223s -----\n",
      "Epochs 826/1000 - Loss: 1.0231975317001343 - Metric: 0.5271397233009338\n",
      "----- 0.214s -----\n",
      "Epochs 827/1000 - Loss: 1.0231975317001343 - Metric: 0.5271395444869995\n",
      "----- 0.196s -----\n",
      "Epochs 828/1000 - Loss: 1.0231975317001343 - Metric: 0.5271397233009338\n",
      "----- 0.202s -----\n",
      "Epochs 829/1000 - Loss: 1.0231974124908447 - Metric: 0.5271400213241577\n",
      "----- 0.201s -----\n",
      "Epochs 830/1000 - Loss: 1.0231975317001343 - Metric: 0.5271407961845398\n",
      "----- 0.21s -----\n",
      "Epochs 831/1000 - Loss: 1.0231974124908447 - Metric: 0.5271413922309875\n",
      "----- 0.204s -----\n",
      "Epochs 832/1000 - Loss: 1.0231975317001343 - Metric: 0.5271413326263428\n",
      "----- 0.195s -----\n",
      "Epochs 833/1000 - Loss: 1.0231975317001343 - Metric: 0.5271410942077637\n",
      "----- 0.195s -----\n",
      "Epochs 834/1000 - Loss: 1.0231974124908447 - Metric: 0.5271407961845398\n",
      "----- 0.198s -----\n",
      "Epochs 835/1000 - Loss: 1.0231974124908447 - Metric: 0.5271410942077637\n",
      "----- 0.2s -----\n",
      "Epochs 836/1000 - Loss: 1.0231975317001343 - Metric: 0.5271415710449219\n",
      "----- 0.206s -----\n",
      "Epochs 837/1000 - Loss: 1.0231974124908447 - Metric: 0.5271419286727905\n",
      "----- 0.204s -----\n",
      "Epochs 838/1000 - Loss: 1.0231974124908447 - Metric: 0.5271422863006592\n",
      "----- 0.188s -----\n"
     ]
    }
   ],
   "source": [
    "recommender_system = RecommenderSystem(movies_dim=1681+1, users_dim=1885+1, rank=10, hidden_dim=32, output_dim=Y_train.shape[1])\n",
    "\n",
    "recommender_system.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0377368927001953 - Metric: 0.5416817665100098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0377369, 0.54168177]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_system.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feda25d5b70>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = recommender_system.history['loss']\n",
    "metric = recommender_system.history['metric']\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title('LOSS')\n",
    "ax1.set_xlabel('iterations')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.plot(loss, marker='.', color='#0F00FF', markersize=1, linestyle='-')\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_title('METRIC')\n",
    "ax2.set_xlabel('iterations')\n",
    "ax2.set_ylabel('metric')\n",
    "ax2.plot(metric, marker='.', color='#0F00FF', markersize=1, linestyle='-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
